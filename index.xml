<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My New Hugo Site</title>
    <link>https://bheisler.github.io/index.xml</link>
    <description>Recent content on My New Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Feb 2017 11:00:00 -0600</lastBuildDate>
    <atom:link href="https://bheisler.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Writing a Raytracer in Rust - Part 1 - First Rays</title>
      <link>https://bheisler.github.io/post/writing-raytracer-in-rust/</link>
      <pubDate>Mon, 20 Feb 2017 11:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/writing-raytracer-in-rust/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Hello! This is part one of a short series of posts on writing a simple raytracer
in Rust. I&amp;rsquo;ve never written one of these before, so it should be a learning
experience all around.&lt;/p&gt;

&lt;p&gt;So what is a raytracer anyway? The short version is it&amp;rsquo;s a computer program that
traces the paths of simulated rays of light through a scene to produce
high-quality 3D-rendered images. Despite that, it also happens to be the simplest
way to render 3D images. Unfortunately, that comes at a cost in render time -
raytracing an image takes much longer than the polygon-based rendering done by
most game engines. This means that raytracing is typically used to produce
&lt;a href=&#34;http://hof.povray.org/&#34;&gt;beautiful still images&lt;/a&gt; or pre-rendered video (eg.
Pixar&amp;rsquo;s &lt;a href=&#34;https://renderman.pixar.com/&#34;&gt;RenderMan&lt;/a&gt; technology).&lt;/p&gt;

&lt;p&gt;For the purposes of this post, I&amp;rsquo;ll assume that you&amp;rsquo;re familiar with what
vectors are and how they work, as well as basic geometry. If you aren&amp;rsquo;t, check
out the first three pages of Scratchapixel&amp;rsquo;s
&lt;a href=&#34;https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/geometry/points-vectors-and-normals&#34;&gt;excellent series&lt;/a&gt;
on geometry and linear algebra. You don&amp;rsquo;t need to know Rust specifically (though
I recommend it, it&amp;rsquo;s a great language) but you should at least be familiar with
C-family programming languages. If you want to build the code however, you will
need to install &lt;a href=&#34;https://rustup.rs/&#34;&gt;Cargo&lt;/a&gt;, which is the standard Rust build
tool.&lt;/p&gt;

&lt;h2 id=&#34;defining-the-scene&#34;&gt;Defining the Scene&lt;/h2&gt;

&lt;p&gt;The first thing to do is decide exactly what our scene (and therefore our
renderer) will be able to handle. For this first post, it won&amp;rsquo;t be much. One
lonely sphere, hanging in the darkness. No lighting, reflection, or transparency.
No other shapes. We&amp;rsquo;ll extend this basic scene over the rest of this series.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start by defining some structures to hold our scene data:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/bf4247cf7921d8c449e3cd62f323519d.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;And a stub render method and simple test case. I&amp;rsquo;m using the
&lt;a href=&#34;https://crates.io/crates/image&#34;&gt;image crate&lt;/a&gt; to set up the image buffer and
write the resulting render to a PNG file. This is all pretty straightforward
except for the position of the sphere - (0.0, 0.0, -5.0). I&amp;rsquo;ll explain that
later.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/1eb2e5fadc9edb680760360ee53f9a78.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;prime-ray-generation&#34;&gt;Prime Ray Generation&lt;/h2&gt;

&lt;p&gt;The basic idea of how a raytracer like this works is that we iterate over every
pixel in the finished image, then trace a ray from the camera out through that
pixel to see what it hits. This is the exact opposite of how real light works,
but it amounts to pretty much the same thing in the end. Rays traced from the
camera are known as prime rays or camera rays. There is actually a lot of
freedom in how we translate pixel coordinates to prime rays, which confused me
for a while, but it&amp;rsquo;s pretty simple if you follow common conventions.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with defining a Ray structure and a static function for generating
prime rays:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/e8f47c4cad5b1210231d66200846f653.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;By convention, the camera is aligned along the negative z-axis, with positive x
towards the right and positive y being up. That&amp;rsquo;s why the sphere is at
(0.0, 0.0, -5.0) - it&amp;rsquo;s directly centered, five units away from the camera.
We&amp;rsquo;ll start by pretending there&amp;rsquo;s a two-unit by two-unit screen one unit in
front of the camera, dividing that into pixels, and using the directions to each
pixel as our rays. We need to translate the (0&amp;hellip;800, 0&amp;hellip;600) coordinates of our
pixels to the (-1.0&amp;hellip;1.0, -1.0&amp;hellip;1.0) coordinates of that screen. I&amp;rsquo;ll start
with the finished code for this step, then explain it in more detail.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/be79c6e0871e4308443c0d4e61318fed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Let&amp;rsquo;s unpack that a bit and focus on just the x component. The y component is
almost exactly the same.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let pixel_center = x as f64 + 0.5;
let normalized_to_width = pixel_center / screen.width as f64;
let adjusted_screen_pos = (normalized_to_width * 2.0) - 1.0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First, we cast to float and add 0.5 (one half-pixel) because we want our ray to
pass through the center (rather than the corner) of the pixel on our imaginary
screen. Then we divide by the screen width to convert from our original
coordinates (0&amp;hellip;800) to (0.0&amp;hellip;1.0). That&amp;rsquo;s almost, but not quite, the
(-1.0&amp;hellip;1.0) coordinates we want, so we multiply by two and subtract one. That&amp;rsquo;s
all there is to it! The y calculation follows the same basic process except the
last step:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let adjusted_screen_pos = 1.0 - (normalized_to_width * 2.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is simply because the image coordinates have positive y meaning down, where
we want positive y to be up. To correct for this, we simply take the negative of
the last step of the calculation.&lt;/p&gt;

&lt;p&gt;Then we pack the x and y components into a vector (z is -1.0 because all
of our prime rays should go forward from the camera) and normalize it to get a
nice direction vector. Simple, right? This is why the 2x2 screen 1 unit from the
camera convention is convenient. If we&amp;rsquo;d used any other set of coordinates than
(-1.0&amp;hellip;1.0, -1.0&amp;hellip;1.0) then the screen would be off center and/or we&amp;rsquo;d have to
do more calculations to avoid distorting the image.&lt;/p&gt;

&lt;p&gt;We could actually stop here - this is a working prime ray generation function.
However, it assumes that the image we&amp;rsquo;re generating is perfectly square and that
the field of view is precisely 90 degrees. It&amp;rsquo;s probably worth adding a
correction for other aspect ratios and different fields of view.&lt;/p&gt;

&lt;p&gt;To adjust for different aspect ratios, we just calculate the aspect ratio and
multiply it by the x coordinate. We&amp;rsquo;re assuming that the image will be wider than
it is tall, but most images are so that&amp;rsquo;s good enough for now. If we didn&amp;rsquo;t do
this, the rays would be closer together in the x direction than in the y, which
would cause a distortion in the image (where every pixel is the same size in
both directions).&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/1bef7641a1ce2e52957f65a9022e6a0f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Then we can add another adjustment for field of view. Field of view is the angle
between the left-most ray and the right-most ray (or top- and bottom-most). We
can use simple trigonometry to calculate how much we need to adjust the
coordinates by:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/477ad79cdb635cee87f6e7672d1bc3dc.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;You might have noticed that the origin of all prime rays is exactly (0, 0, 0).
This means that our camera is fixed at those coordinates. It is possible to adapt
this function to place the camera in different locations or orientations, but
we won&amp;rsquo;t need that for now.&lt;/p&gt;

&lt;h2 id=&#34;testing-for-intersections-with-the-sphere&#34;&gt;Testing for Intersections With The Sphere&lt;/h2&gt;

&lt;p&gt;Now that we have our prime rays, we need to know if they intersect with our
sphere. As usual, we&amp;rsquo;ll start with some definitions.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/5cb206e9d4f0dda63a44c1fa5d2908a2.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The basic idea behind this test is that we construct a right-triangle using the
prime ray as the adjacent side and the line between the origin and the center
of the sphere as the hypotenuse. Then we calculate the length of the opposite
side using the Pythagorean Theorem - if that side is smaller than the radius of
the sphere, the ray must intersect the sphere. In practice, we actually do the
check on length-squared values because square roots are expensive to calculate,
but it&amp;rsquo;s the same idea.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2fd3e237481614d13a34dc184cb5d106.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;finishing-the-render-method&#34;&gt;Finishing the Render Method&lt;/h2&gt;

&lt;p&gt;Now that we have all of the hard parts done, we simply need to integrate these
functions into the render function and produce our image:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/b2f715736405503985ef66f3732746c5.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;After adding some extra glue code to parse a scene definition and save the
rendered image to a file, we get the resulting image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/raytracer-first-render.png&#34; alt=&#34;First Rendered Image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It isn&amp;rsquo;t very impressive yet, but we&amp;rsquo;ll add more detail to it as we go.&lt;/p&gt;

&lt;p&gt;If you want to try playing around with the code yourself, you can check out the
&lt;a href=&#34;https://github.com/bheisler/raytracer&#34;&gt;GitHub Repository&lt;/a&gt;. If you want to learn
more about 3D rendering in general or raytracing in particular, check out
&lt;a href=&#34;https://www.scratchapixel.com/index.php&#34;&gt;Scratchapixel&lt;/a&gt;, which is the resource
I used while working on this.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>