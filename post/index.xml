<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on bheisler.github.io</title>
    <link>https://bheisler.github.io/post/index.xml</link>
    <description>Recent content in Posts on bheisler.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Feb 2018 07:00:00 -0600</lastBuildDate>
    <atom:link href="https://bheisler.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Criterion.rs v0.2 - HTML, Throughput Measurements, API Changes</title>
      <link>https://bheisler.github.io/post/criterion-rs-0-2/</link>
      <pubDate>Mon, 05 Feb 2018 07:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/criterion-rs-0-2/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;m pleased to announce the release of Criterion.rs v0.2, available today. Version 0.2 provides a
number of new features including HTML reports and throughput measurements, fixes a handful of bugs,
and adds a new, more powerful way to configure and construct your benchmarks. It also breaks
backwards compatibility with the 0.1 versions in a number of small but important ways. Read on to
learn more!&lt;/p&gt;

&lt;h2 id=&#34;what-is-criterion-rs&#34;&gt;What is Criterion.rs?&lt;/h2&gt;

&lt;p&gt;Criterion.rs is a statistics-driven benchmarking library for Rust. It provides precise measurements
of changes in the performance of benchmarked code, and gives strong statistical confidence that
apparent performance changes are real and not simply noise. Clear output, a simple API and
reasonable defaults make it easy to use even for developers without a background in statistics.
Unlike the benchmarking harness provided by Rust, Criterion.rs can be used with stable versions of
the compiler.&lt;/p&gt;

&lt;p&gt;If you aren&amp;rsquo;t already using Criterion.rs for your benchmarks, check out the &lt;a href=&#34;https://japaric.github.io/criterion.rs/book/getting_started.html&#34;&gt;Getting Started
guide&lt;/a&gt; or go right to &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;the GitHub
repo&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;new-features&#34;&gt;New Features&lt;/h2&gt;

&lt;p&gt;This is only some of the improvements made to Criterion.rs in v0.2 - for a more complete list, see
the &lt;a href=&#34;https://github.com/japaric/criterion.rs/blob/master/CHANGELOG.md&#34;&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;html-reports&#34;&gt;HTML Reports&lt;/h3&gt;

&lt;p&gt;Criterion.rs now generates an HTML report for each benchmark, including detailed graphs showing the
performance behavior of your code. For an example of the generated report, &lt;a href=&#34;https://japaric.github.io/criterion.rs/book/user_guide/html_report/index.html&#34;&gt;click
here&lt;/a&gt;.
&lt;a href=&#34;http://www.gnuplot.info/&#34;&gt;Gnuplot&lt;/a&gt; must be installed in order to generate reports.&lt;/p&gt;

&lt;p&gt;The reports and other data are now stored in the &lt;code&gt;target/criterion&lt;/code&gt; directory when you run the
benchmarks, which makes them easier to find and means you no longer need to ignore the &lt;code&gt;.criterion&lt;/code&gt;
directory.&lt;/p&gt;

&lt;p&gt;There is still much work to do on expanding the HTML reports, so stay tuned for further enhancements.&lt;/p&gt;

&lt;h3 id=&#34;criterion-bench&#34;&gt;Criterion.bench&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/struct.Criterion.html#method.bench&#34;&gt;&lt;code&gt;bench&lt;/code&gt;&lt;/a&gt;
function has been added to the &lt;code&gt;Criterion&lt;/code&gt; struct, along with two new structures -
&lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/struct.Benchmark.html&#34;&gt;&lt;code&gt;Benchmark&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/struct.ParameterizedBenchmark.html&#34;&gt;&lt;code&gt;ParameterizedBenchmark&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/a&gt;.
These structures provide a powerful builder-style interface to define and configure complex
benchmarks which can perform benchmarks and comparisons that were not possible previously, such as
comparing the performance of a Rust function and an external program over a range of inputs. These
structs also allow for easy per-benchmark configuration of measurement times and other settings.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;c.bench(
    &amp;quot;Fibonacci&amp;quot;,
    Benchmark::new(&amp;quot;Recursive&amp;quot;, |b| b.iter(|| fibonacci_recursive(20)))
        .with_function(&amp;quot;Iterative&amp;quot;, |b| b.iter(|| fibonacci_iterative(20))),
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;throughput-measurements&#34;&gt;Throughput Measurements&lt;/h3&gt;

&lt;p&gt;Criterion.rs can now estimate the throughput of the code under test. By providing a
&lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/enum.Throughput.html&#34;&gt;&lt;code&gt;Throughput&lt;/code&gt;&lt;/a&gt; (for
&lt;code&gt;Benchmark&lt;/code&gt;) or &lt;code&gt;Fn(&amp;amp;T) -&amp;gt; Throughput&lt;/code&gt; (for &lt;code&gt;ParameterizedBenchmark&amp;lt;T&amp;gt;&lt;/code&gt;), you can tell Criterion.rs
how many bytes or elements are being processed in each iteration of your benchmark. Criterion.rs
will then use that information to estimate the number of bytes or elements your code can process per
second.&lt;/p&gt;

&lt;h2 id=&#34;breaking-changes&#34;&gt;Breaking Changes&lt;/h2&gt;

&lt;p&gt;Unfortunately, some breaking changes were necessary to implement these new features.&lt;/p&gt;

&lt;h3 id=&#34;builder-methods-take-self-by-value&#34;&gt;Builder Methods Take self by Value&lt;/h3&gt;

&lt;p&gt;All of the builder methods on &lt;code&gt;Criterion&lt;/code&gt; now take &lt;code&gt;self&lt;/code&gt; by value rather than by mutable reference.
This is to simplify chaining multiple methods after calling &lt;code&gt;Criterion::default()&lt;/code&gt;, but existing
code which configures a &lt;code&gt;Criterion&lt;/code&gt; structure may need to be changed or replaced with code that
configures a &lt;code&gt;Benchmark&lt;/code&gt; instead.&lt;/p&gt;

&lt;h3 id=&#34;static-lifetime-for-closure-types&#34;&gt;&amp;lsquo;static Lifetime For Closure Types&lt;/h3&gt;

&lt;p&gt;Most closures passed to Criterion.rs must now have types that live for the &lt;code&gt;&#39;static&lt;/code&gt; lifetime. Note,
the closures themselves don&amp;rsquo;t need to be &lt;code&gt;&#39;static&lt;/code&gt;, but their types do.&lt;/p&gt;

&lt;p&gt;What does this mean for you? You may need to change your benchmarks from &lt;code&gt;|b| b.iter(...)&lt;/code&gt; to
&lt;code&gt;move |b| b.iter(...)&lt;/code&gt;. This does mean that the closures will take ownership of values used inside
the closure, so you may need to clone or &lt;code&gt;Rc&lt;/code&gt; shared test data. Simple closures, like those in the
Fibonacci example above, can remain unchanged - this only affects closures which capture values
from their environment.&lt;/p&gt;

&lt;h3 id=&#34;benchmark-parameters-must-implement-debug&#34;&gt;Benchmark Parameters Must Implement Debug&lt;/h3&gt;

&lt;p&gt;Previously, Criterion.rs required the values for parameterized benchmarks to implement the &lt;code&gt;Display&lt;/code&gt;
trait. This has been changed to require the &lt;code&gt;Debug&lt;/code&gt; trait instead, as that can be easily derived.&lt;/p&gt;

&lt;h2 id=&#34;thank-you&#34;&gt;Thank You&lt;/h2&gt;

&lt;p&gt;Thank you to Damien Levac (@Proksima), @dowwie, Oliver Mader (@b52), Nick Babcock (@nickbabcock),
Steven Fackler (@sfackler), and @llogiq for suggesting improvements to Criterion.rs since the last
release. I&amp;rsquo;d also like to thank Alexander Bulaev (@alexbool) and Paul Mason (@paupino) for
contributing pull requests.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;d like to see your name up here, or if you have ideas, problems or questions, please consider
contributing to Criterion.rs on &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking In Stable Rust With Criterion.rs</title>
      <link>https://bheisler.github.io/post/benchmarking-with-criterion-rs/</link>
      <pubDate>Fri, 12 Jan 2018 19:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/benchmarking-with-criterion-rs/</guid>
      <description>

&lt;p&gt;When I initially announced the release of Criterion.rs, I didn&amp;rsquo;t expect that
there would be so much demand for benchmarking on stable Rust. Now, I&amp;rsquo;d like to
announce the release of Criterion.rs 0.1.2, which supports the stable compiler.
This post is an introduction to benchmarking with Criterion.rs and a discussion
of reasons why you might or might not want to do so.&lt;/p&gt;

&lt;h2 id=&#34;what-is-criterion-rs&#34;&gt;What is Criterion.rs?&lt;/h2&gt;

&lt;p&gt;Criterion.rs is a benchmarking library for Rust that aims to bring solid
statistical confidence to benchmarking Rust code, while maintaining good
ease-of-use, even for programmers without a background in statistics. It&amp;rsquo;s
already available on &lt;a href=&#34;https://crates.io/crates/criterion&#34;&gt;Crates.io&lt;/a&gt; and on
&lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It was originally written by &lt;a href=&#34;https://github.com/japaric/&#34;&gt;@japaric&lt;/a&gt;, but was
never released on Crates.io. I (&lt;a href=&#34;https://github.com/bheisler&#34;&gt;@bheisler&lt;/a&gt;)
volunteered to take over maintenance and development a few months ago, and I
published the first version of Criterion.rs to Crates.io in December 2017.&lt;/p&gt;

&lt;h2 id=&#34;getting-started-with-criterion-rs&#34;&gt;Getting Started with Criterion.rs&lt;/h2&gt;

&lt;p&gt;To start with Criterion.rs, add the following to your &lt;code&gt;Cargo.toml&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dev-dependencies]
criterion = &amp;quot;0.1.2&amp;quot;

[[bench]]
name = &amp;quot;my_benchmark&amp;quot;
harness = false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, define a benchmark by creating a file at &lt;code&gt;$PROJECT/benches/my_benchmark.rs&lt;/code&gt; with the following contents.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2da10e7aaac3011ce1d6328e3a4ffdce.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Finally, run this benchmark with &lt;code&gt;cargo bench&lt;/code&gt;. You should see output similar to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     Running target/release/deps/example-423eedc43b2b3a93
fib 20                  time:   [26.029 us 26.251 us 26.505 us]
Found 11 outliers among 99 measurements (11.11%)
  6 (6.06%) high mild
  5 (5.05%) high severe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See the &lt;a href=&#34;https://japaric.github.io/criterion.rs/book/getting_started.html&#34;&gt;Getting Started&lt;/a&gt; guide for more details.&lt;/p&gt;

&lt;h2 id=&#34;converting-libtest-benchmarks-to-criterion-rs&#34;&gt;Converting libtest benchmarks to Criterion.rs&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll start with this benchmark as an example:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/61efe654cf235acab9966f8e3e55a5c3.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The first thing to do is update the &lt;code&gt;Cargo.toml&lt;/code&gt; to disable the libtest
benchmark harness:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[bench]]
name = &amp;quot;example&amp;quot;
harness = false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next step is to update the imports:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#[macro_use]
extern crate criterion;
use criterion::Criterion;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, we can change the &lt;code&gt;bench_fib&lt;/code&gt; function. Remove the &lt;code&gt;#[bench]&lt;/code&gt; and change
the argument to &lt;code&gt;&amp;amp;mut Criterion&lt;/code&gt; instead. The contents of this function need to
change as well:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn bench_fib(c: &amp;amp;mut Criterion) {
    c.bench_function(&amp;quot;fib 20&amp;quot;, |b| b.iter(|| fibonacci(20)));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we need to invoke some macros to generate a main function, since we
no longer have libtest to provide one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;criterion_group!(benches, bench_fib);
criterion_main!(benches);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that&amp;rsquo;s it! The complete migrated benchmark code is below:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/45675855d119ad6f03fa94a5247466fe.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;the-pitch-why-you-might-want-to-use-criterion-rs&#34;&gt;The Pitch - Why You Might Want to Use Criterion.rs&lt;/h2&gt;

&lt;p&gt;There are a number of reasons to use Criterion.rs.&lt;/p&gt;

&lt;p&gt;The biggest one, the one that drew me to it in the first place, is the
statistical confidence it provides. libtest gives a number and a confidence
interval of some sort, but I cant&amp;rsquo;t even tell if that number is higher or
lower than it was the last time I ran the benchmarks. Even if it is, how could
I tell if that change was due to random noise or a change in the performance of
the code? I&amp;rsquo;ve used Criterion.rs to benchmark and optimize my own projects and
every time I&amp;rsquo;ve seen it show a statistically-significant optimization or
regression it&amp;rsquo;s been real. It&amp;rsquo;s almost fun, tweaking the code and running the
benchmarks to see what happened. I&amp;rsquo;ve never gotten into that sort of flow with
libtest.&lt;/p&gt;

&lt;p&gt;Another big reason is that Criterion.rs is actively maintained and developed.
libtest is not, and the description of the bencher crate on GitHub declares
that new features will not be added. Indeed, it instructs the reader to &amp;ldquo;Go
build a better stable benchmarking library.&amp;rdquo; I hope Criterion.rs is that
library.&lt;/p&gt;

&lt;p&gt;Criterion.rs produces more statistical information than libtest, and generates
helpful charts and graphs to make it more easily understandable to the user.
Additionally, it automatically compares the results of one run with the
previous, without needing to install cargo-benchcmp or manually save benchmark
results to files.&lt;/p&gt;

&lt;p&gt;Finally, Criterion.rs is compatible with stable builds of Rust, where libtest is
not.&lt;/p&gt;

&lt;h2 id=&#34;the-anti-pitch-why-you-might-prefer-libtest&#34;&gt;The Anti-Pitch - Why You Might Prefer libtest&lt;/h2&gt;

&lt;p&gt;With all that said, I would also like to explain some reasons why Criterion.rs
might not be right for everyone.&lt;/p&gt;

&lt;p&gt;For example, libtest benchmarks execute much more quickly than
Criterion.rs benchmarks, especially the small and fast benchmarks. A small
libtest benchmark function can run to completion in less than a second, where
Criterion runs for (by default) at least 8 seconds plus analysis time. If your
project lends itself to many small benchmarks, you&amp;rsquo;d need to configure
Criterion.rs to run shorter tests, where you wouldn&amp;rsquo;t with libtest.&lt;/p&gt;

&lt;p&gt;The corollary to active development is that Criterion.rs&amp;rsquo; API is not yet fully
stablized, where libtest isn&amp;rsquo;t likely to change.&lt;/p&gt;

&lt;p&gt;libtest is also more seamless to use than Criterion.rs. You don&amp;rsquo;t need to mess
around with your &lt;code&gt;Cargo.toml&lt;/code&gt; file to use libtest benchmarks, they just work.
Along the same lines, libtest has the &lt;code&gt;test::black_box&lt;/code&gt; function to prevent
unwanted constant folding, which Criterion.rs can only approximate for now.
Finally, libtest is the only option for benchmarks within your main crate -
both Criterion.rs and bencher can only be used in the &lt;code&gt;benches&lt;/code&gt; folder at
present.&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;I hope I&amp;rsquo;ve convinced you to give Criterion.rs a look. I&amp;rsquo;m excited for the
future of this project and of Rust as a whole, and I hope you are too.&lt;/p&gt;

&lt;p&gt;Although Criterion.rs now supports stable Rust, that doesn&amp;rsquo;t mean that it
itself is stable, or even feature-complete. I certainly plan to continue
polishing and expanding on what Criterion.rs already provides. If you&amp;rsquo;d like to
help with that effort, or if you&amp;rsquo;d like to make suggestions, feature requests
or bug reports, please check out &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;the repository on
GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In addition, I hope to work with the Rust team to help define and implement the
necessary changes to Cargo and rustc to use alternate test and benchmark
frameworks. This would make it as seamless to use Criterion.rs as it already is
to use libtest, and will hopefully allow the community to experiment with a
variety of ways to support testing and benchmarking.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Are Benchmarks From Cloud CI Services Reliable?</title>
      <link>https://bheisler.github.io/post/benchmarking-in-the-cloud/</link>
      <pubDate>Sat, 06 Jan 2018 16:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/benchmarking-in-the-cloud/</guid>
      <description>

&lt;p&gt;After I released the first version of &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;Criterion.rs&lt;/a&gt;,
(a statistics-driven benchmarking tool for Rust) I was asked about using it to
detect performance regressions as part of a cloud-based continuous integration
(CI) pipeline such as Travis-CI or Appveyor. That got me wondering - does it
even make sense to do that?&lt;/p&gt;

&lt;p&gt;Cloud-CI pipelines have a lot of potential to introduce noise into the benchmarking
process - unpredictable load on the physical hosts of the build VM&amp;rsquo;s, or
even unpredictable migrations of VMs between physical hosts. How much
noise is there really, and how much does it affect real-world benchmarks? I
couldn&amp;rsquo;t find any attempt to answer that question with real data, so I decided
to do it myself.&lt;/p&gt;

&lt;p&gt;tl;dr: Yes, there is enough noise to make benchmark results unreliable.
Read on if you want to see the numbers.&lt;/p&gt;

&lt;p&gt;In this post, I benchmarked on Travis-CI, but I don&amp;rsquo;t mean to single them out,
they&amp;rsquo;re just the cloud-CI provider that I&amp;rsquo;m most familiar with.
To the best of my knowledge, they don&amp;rsquo;t claim that their service is suitable
for benchmarking.&lt;/p&gt;

&lt;h2 id=&#34;methodology&#34;&gt;Methodology&lt;/h2&gt;

&lt;p&gt;Before I can test the effects of the cloud-CI environment on benchmarks, I need
some benchmarks. I opted to use the existing benchmark suite of Rust&amp;rsquo;s
&lt;a href=&#34;https://github.com/rust-lang/regex&#34;&gt;regex library&lt;/a&gt;, because it&amp;rsquo;s a well-known,
well-regarded and high-performance codebase. Specifically, I used the &amp;ldquo;rust&amp;rdquo;
benchmark suite. The regex project&amp;rsquo;s benchmarks use Rust&amp;rsquo;s standard &lt;a href=&#34;https://github.com/rust-lang/rust/tree/master/src/libtest&#34;&gt;&lt;code&gt;libtest&lt;/code&gt;
benchmark/test harness&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I ran the benchmarks in pairs, as suggested in &lt;a href=&#34;https://beachape.com/blog/2016/11/02/rust-performance-testing-on-travis-ci/&#34;&gt;this post by BeachApe&lt;/a&gt;.
However, that post suggests running one benchmark with master and one with a
pull-request branch - all of my benchmarks were done with the same version of the
code to prevent changes to the code from affecting the results. For the cloud
benchmarks, each pair was run in a separate build job on Travis-CI.&lt;/p&gt;

&lt;p&gt;I wrote a script to run 100 such pairs of builds on an old desktop machine I
had laying around, and another to run 100 Travis-CI builds by editing, committing
and force-pushing an unused file, then downloading the resulting build log.
Note that I did edit the Travis build script to only perform the necessary
compilation and benchmarking, to avoid using more of Travis-CI&amp;rsquo;s resources than
was necessary. A few of the resulting log files were damaged and were replaced
with log files from new builds at the end. There were a number of occasions where
parts of the logs from Travis-CI were missing or corrupted and I am not certain
that I found all of them.&lt;/p&gt;

&lt;p&gt;Each pair was then compared using &lt;a href=&#34;https://github.com/BurntSushi/cargo-benchcmp&#34;&gt;cargo benchcmp&lt;/a&gt;
and the percentage differences were extracted with more scripts.&lt;/p&gt;

&lt;p&gt;The pairwise benchmarking approach has a few advantages. First, by running both
benchmarks on the same physical machine (for local benchmarks) or the same
build job (for cloud benchmarks), all effects which are constant for the length
of a benchmark pair can be ignored. This includes differences in the performance
of the physical hosts or differences in compiler versions, since we&amp;rsquo;re only
looking at the percentage change between two consecutive benchmarks. Using the
percentage differences also controls for some benchmarks naturally taking longer
than others.&lt;/p&gt;

&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/travis_benchmark_histogram.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;As you can see from the above chart, the cloud benchmarks do indeed show more
noise than the local benchmarks.&lt;/p&gt;

&lt;p&gt;All numbers are in units of percentage points representing the percentage
difference between the two benchmarks of a pair:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Local:
mean: 0.0315897959184
min: -24.6, max: 22.18
std. dev.: 2.11411179379

Cloud:
mean: 1.42961542492
min: -99.99, max: 3177.03
std. dev.: 72.1539676978

Levene&#39;s Test p-value: 1.97E-49
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that there were four benchmark results in the cloud set with percentage
differences greater than 10,000% which I&amp;rsquo;ve removed as outliers. Those were not
included in the calculations above; if they were included the cloud numbers would be
substantially worse. I opted to remove them after inspecting them and finding
inconsistencies in those benchmark results which lead me to suspect that the
logs were damaged. For example, one benchmark shows the time for each iteration
increased by more than 200x but the throughput for the same benchmark
appears to have increased slightly, rather than decreased as one would expect.&lt;/p&gt;

&lt;p&gt;Additionally, manual inspection of the comparison results shows that sometimes
multiple consecutive benchmark tests within a single run of the benchmarks
all differ from their pair by a large and consistent value. This could indicate
something is slowing down the build VM by a significant degree and persisting
long enough to affect multiple benchmark tests.&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;The greatly increased variance of benchmarks done in the cloud casts doubt on
the reliability of benchmarks performed on cloud-CI pipelines. This confirms the
intuitive expectation.&lt;/p&gt;

&lt;p&gt;To be clear; this doesn&amp;rsquo;t mean every benchmark is wrong - many of the comparisons
show shifts of +-2%, roughly similar to the noise observed in local benchmarks.
However, differences of as much as 50% are fairly common with no change
in the code at all, which makes it very difficult to know if a change
in benchmarking results is due to a change in the true performance of the code
being benchmarked, or if it is simply noise. Hence, unreliable.&lt;/p&gt;

&lt;p&gt;It would still be useful to have automated detection of performance regressions
as part of a CI pipeline, however. Further work is needed to find ways to
mitigate the effects of this noise.&lt;/p&gt;

&lt;p&gt;One way to reduce noise in this system would be to execute each benchmark suite
two or more times with each version of the code and accept the one with the
smallest mean or variance before comparing the two. In this case, it would be
best to run each benchmark suite to completion before running it again rather
than running each test twice consecutively, to reduce the chance that some
external influence affects a single test twice.&lt;/p&gt;

&lt;p&gt;A simpler, though more manual, method to accomplish the same thing would be to
run the whole benchmarking process in multiple build jobs. In that case, before
merging a pull request, a maintainer could manually examine the results. If a
performance regression is detected by all of the build jobs, it&amp;rsquo;s probably safe
to treat it as real rather than noise.&lt;/p&gt;

&lt;p&gt;It is also possible that different cloud-CI providers could make for less noisy
benchmarking environments, though I haven&amp;rsquo;t measured that.&lt;/p&gt;

&lt;p&gt;All of the data and analysis scripts can be found &lt;a href=&#34;https://github.com/bheisler/travis-benchmark-data&#34;&gt;on GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thank you to Daniel Hogan, for reading over this post and giving me a great deal
of useful feedback. I&amp;rsquo;d also like to thank Andrew Gallant (@burntsushi) and co.
for creating both the regex crate and cargo-benchcmp.&lt;/p&gt;

&lt;h2 id=&#34;addendum-why-libtest-and-not-criterion-rs&#34;&gt;Addendum: Why libtest and not Criterion.rs&lt;/h2&gt;

&lt;p&gt;I opted to use Rust&amp;rsquo;s standard benchmarking tool rather than Criterion.rs because
there are no large, well-regarded projects using Criterion.rs to perform their
benchmarks at present.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t know whether using Criterion.rs would change these results or not.
Criterion&amp;rsquo;s analysis process is different enough that it might, but until I have
data one way or another I intend to advise users not to trust cloud benchmarks
based on Criterion.rs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Penny&#39;s Sword - RWBY - Part 2</title>
      <link>https://bheisler.github.io/post/pennys-sword-rwby-part2/</link>
      <pubDate>Thu, 19 Oct 2017 19:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/pennys-sword-rwby-part2/</guid>
      <description>

&lt;p&gt;Salutations! Welcome to the second part of my post on my replica of Penny&amp;rsquo;s
Sword from Rooster Teeth&amp;rsquo;s animated web show RWBY. If you haven&amp;rsquo;t read &lt;a href=&#34;https://bheisler.github.io/post/pennys-sword-rwby-part1/&#34;&gt;part
1&lt;/a&gt;, go ahead and check it out. When we left
off, most of the parts were shaped and primed but not yet assembled. This time
we&amp;rsquo;ll get into the painting, and some of it might be hard to visualize so take
a look at the
&lt;a href=&#34;http://rwby.wikia.com/wiki/Penny&#39;s_Swords/Image_Gallery?file=Turnaround_1.png&#34;&gt;tournarounds&lt;/a&gt;
if you&amp;rsquo;re not sure what I mean. Without further ado&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;blade-guard-and-grip&#34;&gt;Blade, Guard and Grip&lt;/h2&gt;

&lt;p&gt;The blade and grip needed to sit perfectly flush with the guard, and the
easiest way to fix parts that don&amp;rsquo;t quite fit together is &lt;a href=&#34;http://mattmunson.blogspot.ca/2007/11/bondo-squish.html&#34;&gt;The Bondo
Squish&lt;/a&gt;. This is a
very versatile technique, well worth keeping in your bag of tricks. The basic
idea is that you spread Bondo on one object, coat the other in something the
Bondo won&amp;rsquo;t stick to, and squish them together. Let the Bondo cure for an hour
or so and then you can separate them, clean up the squeeze-out and now you have
an inverse mold of one object in the surface of the other. I&amp;rsquo;ve also used this
trick to straighten up lines on parts by clamping them to the flat surface of
my workbench. In this case, I used regular scotch tape on the guard ring and
sprayed on a bit of old mold release. I had to repeat the process several times
for the joint between the blade and the guard to build up enough Bondo to fill
the entire gap, but in the end it worked out quite nicely. The steel rod in the
center of the blade provided good registration to keep the guard in the right
place each time. Once I was satisfied, I epoxied these three parts together
permanently.&lt;/p&gt;

&lt;p&gt;At this point, I was able to hold the sword by the handle - the steel core means
it&amp;rsquo;s quite able to support its own weight. That weight is considerable - MDF and
steel aren&amp;rsquo;t light. I wouldn&amp;rsquo;t want to have to carry this around a convention
floor all weekend, but it works fine as a shelf piece.&lt;/p&gt;

&lt;h2 id=&#34;learning-to-solder&#34;&gt;Learning to Solder&lt;/h2&gt;

&lt;p&gt;At this point, I knew I had to install the EL wire in the blade. In a perfect
world, I would have waited until after the painting was done, but this sword
has some parts that had to be constructed on top of the light diffusers, so that
wasn&amp;rsquo;t an option.&lt;/p&gt;

&lt;p&gt;I got my EL Wire from &lt;a href=&#34;http://www.coolneon.com/&#34;&gt;CoolNeon&lt;/a&gt;, and they live up to
their name. I made the rookie mistake of forgetting to order connectors to
attach the wire to the driver and they included four of them for free with a
nice note in the package. Shipping costs from California to Canada are pretty
rough, but the wire is tough, bright and easy to work with.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re not familiar, EL wire works like this. You connect a battery to a
piece of electronics called a driver, which is then wired (either through
connectors or directly soldered) to the wire itself. Different drivers can
power different amounts of EL wire - I went with one of the smallest ones
because I wanted to hide the driver and battery inside the guard. CoolNeon
sells the wire pre-soldered, but that costs extra and I wanted to learn how to
solder anyway.&lt;/p&gt;

&lt;p&gt;It turns out to be pretty easy. I bought a soldering iron, some solder and some
copper wire to practice on at my local hardware store, watched some YouTube
videos on soldering (good examples are &lt;a href=&#34;https://www.youtube.com/watch?v=SQUiuyUY8pQ&#34;&gt;this one by
PunishedProps&lt;/a&gt; and &lt;a href=&#34;https://www.youtube.com/watch?v=Tsl5OW_w2JY&#34;&gt;this one by
CoolNeon&lt;/a&gt;). After a couple of
tries, I pretty much had it figured and I was able to complete the soldering
for the first two pieces of EL wire in about an hour.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-wire.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;I glued the two strips of wire into the grooves on the blade with thin CA,
scuffed up the clear acrylic light diffusers with some sandpaper and glued
those in as well with epoxy. They didn&amp;rsquo;t sit quite flush owing to my mixup with
the groove depth earlier, but it&amp;rsquo;s good enough.&lt;/p&gt;

&lt;h2 id=&#34;side-details&#34;&gt;Side Details&lt;/h2&gt;

&lt;p&gt;This sword has some extra little black- and copper-colored details on the side
of the blade where it folds in half to become a gun (Of course it&amp;rsquo;s also a gun.
Every weapon is RWBY is a gun somehow.) Of course, mine doesn&amp;rsquo;t transform but
it&amp;rsquo;s important to look as though it could. This wasn&amp;rsquo;t too hard. I used a
&lt;a href=&#34;http://amzn.to/2ztH6bS&#34;&gt;plastic scoring knife&lt;/a&gt; and some chisel work to cut out
a couple of window shapes in 1mm styrene and glued them to solid squares of
thinner styrene with &lt;a href=&#34;http://amzn.to/2zud33J&#34;&gt;Bondene&lt;/a&gt; (not to be confused with
Bondo. Great naming, folks). Then I cut a thin strip of 1mm styrene and, with a
lot of CA and filing, cut it into parts and made a continuous strip around the
middle of the blade. Then I glued on the square window-things I&amp;rsquo;d made.
Finally, I used a &lt;a href=&#34;http://amzn.to/2ysJmS9&#34;&gt;razor saw&lt;/a&gt; to make a thin cut
through the styrene all the way around the blade to make it look like the blade
was segmented. At this point, everything was done and ready for paint.&lt;/p&gt;

&lt;h2 id=&#34;painting-the-grip&#34;&gt;Painting the Grip&lt;/h2&gt;

&lt;p&gt;I started the painting process by masking off the guard ring. I always use the
good (if expensive) &lt;a href=&#34;http://amzn.to/2glSTnI&#34;&gt;Tamiya masking tape&lt;/a&gt; to start with
- I&amp;rsquo;ve found it works better at preventing leaks, handles curves better and
never pulls up paint. Of course, I&amp;rsquo;m also cheap, so I fill in the rest with
regular hardware store masking tape and paper towel.&lt;/p&gt;

&lt;p&gt;For the grip, I went with the &lt;a href=&#34;http://amzn.to/2xJEF7X&#34;&gt;plain grey primer&lt;/a&gt; as
the color for the raised sections (hey, if it works&amp;hellip;) and Montana Gold&amp;rsquo;s
Stealth Grey for the inner section (I&amp;rsquo;m not giving an Amazon link for that one
because the prices are outrageous. If you&amp;rsquo;re in Saskatoon, buy it from &lt;a href=&#34;http://www.artplacement.com/artstore/&#34;&gt;Art
Placement Art Supplies&lt;/a&gt; instead).
Montana Gold is good spray paint, but their cans tend to lay down very thick
coats that don&amp;rsquo;t dry very smoothly, so I prefer to decant the paint and spray
it through my airbrush instead. I use a &lt;a href=&#34;http://amzn.to/2ysKIfH&#34;&gt;Model Master
B22&lt;/a&gt;, but to be honest that&amp;rsquo;s a lot more fancy than I
really needed - I got it on sale, but I&amp;rsquo;d recommend sticking with something
cheaper and simpler. I don&amp;rsquo;t have a good way to decant the paint except to
spray it by hand into a glass jar, so if you have any better ideas I&amp;rsquo;d love to
hear them.&lt;/p&gt;

&lt;p&gt;At first, I coated the whole grip with the Stealth Grey, masked the inner
portion and added the light grey primer, but the cheap masking tape pulled up
the thin layer of stealth grey. Then I realized that I&amp;rsquo;d done it exactly
backwards. I coated the whole thing in light grey primer, masked out the raised
sections and added the stealth grey. After removing the masking tape and giving
the whole grip a coat of Montana Gold matte varnish (right from the can) I
moved on to the guard.&lt;/p&gt;

&lt;h2 id=&#34;painting-the-guard&#34;&gt;Painting the Guard&lt;/h2&gt;

&lt;p&gt;The guard of Penny&amp;rsquo;s sword is a bright orange copper color. I wasn&amp;rsquo;t able to
match it quite right (if you&amp;rsquo;re following along at home I&amp;rsquo;d suggest spraying
the copper on top of an orange-ish base coat) but it worked well enough I
guess. I started by wet-sanding the guard to 600 grit. Honestly, I probably
should have gone higher. For a convincing smooth-metal finish, you want even
the primer to be as smooth as you can get it.&lt;/p&gt;

&lt;p&gt;I started by airbrushing on a couple of coats of &lt;a href=&#34;http://amzn.to/2zfjBCf&#34;&gt;Alclad Gloss Black
Base&lt;/a&gt;. The glossy paint provides a smooth surface to
build the metal layer on. After that, I used &lt;a href=&#34;http://amzn.to/2xK1LpX&#34;&gt;Alclad II
Copper&lt;/a&gt; for the shiny copper layer and &lt;a href=&#34;http://amzn.to/2hKCWUS&#34;&gt;Alclad Aqua
Gloss&lt;/a&gt; for the clear coat. If you&amp;rsquo;re in Saskatoon, you
can buy all of these Alclad paints cheaper at &lt;a href=&#34;http://www.expresshobbies.com/&#34;&gt;Express
Hobbies&lt;/a&gt;, but they&amp;rsquo;re often sold out.&lt;/p&gt;

&lt;p&gt;Overall, this worked quite well. I&amp;rsquo;m very pleased with the Alclad paints - they
spray well, cover well and look great. The Aqua Gloss does have a sort of
plastic-like texture to it that doesn&amp;rsquo;t feel as much like metal as the bare paint
does, but that&amp;rsquo;s a pretty small issue.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-copper.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h2 id=&#34;painting-the-blade&#34;&gt;Painting the Blade&lt;/h2&gt;

&lt;p&gt;The blade has the most complex paint job of the build, but mostly because it has
a lot of small areas that needed to be done separately. To start with, the most
important bit is to avoid getting any paint on the acrylic light diffuser, so
I masked that off straight away.&lt;/p&gt;

&lt;p&gt;I started with a generous coat of stealth grey for the whole blade, again using
my airbrush to put down a finer coat than the spray can would have done. Volpin
Props&amp;rsquo; &lt;a href=&#34;http://www.volpinprops.com/product/painting-and-weathering-for-props-and-replicas-ebook/&#34;&gt;Painting and Weathering for Props and
Replicas&lt;/a&gt;
book has a technique where you can bring up a bit of gloss on dark grey or black
matte paint by rubbing it with cloth covered in charcoal dust. I couldn&amp;rsquo;t get it
to work here. Maybe I was using the wrong charcoal. Anyway, I left the sides of
the blade with the stealth grey and moved on to the edge.&lt;/p&gt;

&lt;p&gt;Another trick I learned from Volpin&amp;rsquo;s book is how to create a brushed-metal look
with Testor&amp;rsquo;s Buffable Metalizer lacquers. I&amp;rsquo;ll not give away the secret here
(Volpin&amp;rsquo;s book is well worth the 8$) but it worked beautifully. I used the
&lt;a href=&#34;http://amzn.to/2zdoxYw&#34;&gt;Aluminum&lt;/a&gt; and &lt;a href=&#34;http://amzn.to/2yOUj1M&#34;&gt;Titanium&lt;/a&gt; shades
on top of the same Alclad gloss black as a base, then sealed it with the Metalizer
sealer. Other details on the blade were done with the same cast of colors and
techniques I&amp;rsquo;ve already mentioned - matte black primer for the styrene detils,
light grey primer for the end of the rail on the spine, gloss black, copper and
aqua gloss for the copper bits and aluminum metalizer for the little section
where the spine of the blade meets the guard. I did mistakenly mix the metalizer
with sealer rather than thinner for that last bit, but it seemed to work alright
anyway. I couldn&amp;rsquo;t shine the resulting paint by buffing it, but it&amp;rsquo;s not a big
deal.&lt;/p&gt;

&lt;p&gt;Overall, I think I like the Alclad paints more than the Testors, but I don&amp;rsquo;t know
if the Alclad paints would work for the brushed-metal trick or not, so might be
best to have both.&lt;/p&gt;

&lt;p&gt;I didn&amp;rsquo;t do much weathering on this build because I wanted to match RWBY&amp;rsquo;s
bright and clean art style. I did a bit of silver dry-brushing around the line
between the brushed-metal effect of the edge of the blade and the dark grey of
the sides, but I think I did too much there. It&amp;rsquo;s easy to go too far with
dry-brushing, I find.&lt;/p&gt;

&lt;h2 id=&#34;guard-covers&#34;&gt;Guard Covers&lt;/h2&gt;

&lt;p&gt;The guard on Penny&amp;rsquo;s Sword has these complex little power-symbol icons on
either side. I couldn&amp;rsquo;t cut something that perfect by hand, so I used lasercut
MDF and acrylic. The power symbol is constructed out of a piece of MDF with the
symbol cut out, and two small pieces of acrylic to fit in those holes and a
larger acrylic ring to hold the power symbols and fit into the guard. These
power symbols have to light up, so they have EL wire inside as well.&lt;/p&gt;

&lt;p&gt;To start with, I primed the flat rings, painted them stealth grey and
clear-coated them with matte varnish. The MDF power symbols were painted with
gloss black and clear-coated with aqua gloss. I set the power symbols face-down
on my workbench, slid the acrylic power-symbol parts into them and glued them
in place with hot glue. CA wouldn&amp;rsquo;t have worked well - it clouds the surface of
acrylic too much and would have run through the gaps and stuck everything to my
workbench - but ordinary hot glue was thick enough and clear enough to work just
right. I glued the power symbols to the guard covers with epoxy. I did have to
redo one of them twice due to mistakes (make sure everything is lined up before
you glue things together!) but I got there in the end.&lt;/p&gt;

&lt;p&gt;After that, it was smooth sailing. I hot-glued down some more EL wire to the
backs of the power symbols, soldered on the connectors and I was ready for final
assembly.&lt;/p&gt;

&lt;h2 id=&#34;final-assembly&#34;&gt;Final Assembly&lt;/h2&gt;

&lt;p&gt;Most of the sword was already together so this was limited to putting the guard
covers in place, hooking up the electronics and gluing on a couple of extra
bits. There is one thing to note though. Although I had enough space inside the
guard for the battery and driver (though I had to cut out part of the guard to
make room for the battery) I didn&amp;rsquo;t leave enough space for all of the wiring
and connectors. Sadly, I can&amp;rsquo;t actually close the guard with everything inside,
so I&amp;rsquo;ll have to leave some of the guts hanging out when I want to light it up.
Anyway, you probably want to see some pictures of the final result, so here you
go:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-finished.jpg&#34; alt=&#34;It looks positively Combat Ready!&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        It looks positively Combat Ready!
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-finished-glow.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Thanks for reading! This build took me about six months, but I had a lot of fun
with it and learned a ton of new stuff - soldering, lasercutting, airbrushing.
Whether you&amp;rsquo;re building your own replica of Penny&amp;rsquo;s Sword or just interested in
learning more about propmaking, I hope you found this useful. Cheers!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Penny&#39;s Sword - RWBY - Part 1</title>
      <link>https://bheisler.github.io/post/pennys-sword-rwby-part1/</link>
      <pubDate>Sat, 14 Oct 2017 12:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/pennys-sword-rwby-part1/</guid>
      <description>

&lt;p&gt;In this post, I&amp;rsquo;ll show you how I built a light-up replica of Penny Polendina&amp;rsquo;s
unnamed swords from Rooster Teeth&amp;rsquo;s excellent animated web show
&lt;a href=&#34;http://www.roosterteeth.com/show/rwby&#34;&gt;RWBY&lt;/a&gt;. RWBY is what originally got me
into propmaking - I&amp;rsquo;ve already made Yang&amp;rsquo;s Ember Celica shotgauntlets and
Adam&amp;rsquo;s Wilt &amp;amp; Blush Sword/Shotgun Combo. This is the first time I&amp;rsquo;ve documented
my process, so hopefully you find it useful.&lt;/p&gt;

&lt;h2 id=&#34;blueprints-design&#34;&gt;Blueprints &amp;amp; Design&lt;/h2&gt;

&lt;p&gt;First, a quick overview of how I intended to do this build. A lot of this plan
didn&amp;rsquo;t survive contact with reality, but I think it&amp;rsquo;s helpful to show where
things went off the rails. The plan was to make the blade out of two pieces of
&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;&amp;rdquo; MDF laminated together around a steel rod, to have a secure place to
attach the hilt and guard. The light-up detail along the blade would be done
with EL wire or LEDs covered by a thin layer of scratched-up acrylic glass to
diffuse the light. The other details on the blade would mostly be made of wood,
MDF and styrene. I wasn&amp;rsquo;t sure how to cut or sand the bevel for the edge of the
blade, planning to figure that out when I got there. The guard was difficult -
it&amp;rsquo;s a more complex shape than it appears. It isn&amp;rsquo;t just a disk - the center is
dished in a bit. I also needed it to be hollow, since that&amp;rsquo;s where I&amp;rsquo;d put the
batteries and electronics to make it light up. The right way to do it is with a
lathe, but I don&amp;rsquo;t have a lathe or any idea how to use one. The hilt would also
be a challenge - it&amp;rsquo;s oval shaped, not round. I planned to cut it out of a
wooden dowel with a spokeshave and make the extra details out of styrene,
planning to fall back to 3D printing if that didn&amp;rsquo;t work.&lt;/p&gt;

&lt;p&gt;As usual, I started by finding reference material and tracing out some
blueprints in Inkscape. Reference material for RWBY is usually pretty easy to
find, since Rooster Teeth often releases detailed turnaround shots of the
characters and their gear for exactly this purpose. The RWBY wiki features &lt;a href=&#34;http://rwby.wikia.com/wiki/Penny%27s_Swords/Image_Gallery&#34;&gt;a
number of images&lt;/a&gt; of
Penny&amp;rsquo;s swords, incuding detailed concept art and a &amp;lsquo;turnaround&amp;rsquo; which shows
the animation of the swords transforming.&lt;/p&gt;

&lt;h2 id=&#34;blade&#34;&gt;Blade&lt;/h2&gt;

&lt;p&gt;This is the part I did last fall. I took a big block of &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;&amp;rdquo; MDF to my &lt;a href=&#34;http://sktechworks.ca/&#34;&gt;local
makerspace&lt;/a&gt; and put it on the CNC mill. I came up with
some plan to use the manual control mode of the mill to cut the block into two
halves of the blade, which I would then glue together. I milled a &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&amp;rdquo; round
groove down the center of the inside of the blade to hold a steel rod for
reinforcement. Then I flipped each piece over and milled a second groove on the
outside of the blade for the light-up section. Unfortunately, I&amp;rsquo;ve completely
forgotten the exact process I used to do this so I can&amp;rsquo;t give more details.
I&amp;rsquo;ll take better notes next time.&lt;/p&gt;

&lt;p&gt;Fast forward six months or so and it&amp;rsquo;s time to glue this thing together. I
scuffed up the in-sides of the MDF and the steel rod with sandpaper so the glue
would hold better and then covered it in wood glue and epoxy and clamped the
pieces together. This turned out to be a mistake. In my haste to get everything
together before the epoxy started to set, I didn&amp;rsquo;t line up the two parts
properly. They&amp;rsquo;re not even close. This isn&amp;rsquo;t the first time I&amp;rsquo;d make a costly
mistake with glues, either.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-shame.jpg&#34; alt=&#34;Those lines should line up.&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Those lines should line up.
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;


&lt;p&gt;D&amp;rsquo;oh. I also realized that the grooves I&amp;rsquo;d cut to hold the acrylic light
diffuser and EL wire are only 2-3mm deep - much too shallow to contain both the
2mm acrylic sheet and the 2.6mm EL wire. Double D&amp;rsquo;oh. I decided to attempt to
repair the damage rather than just starting over.&lt;/p&gt;

&lt;p&gt;I placed a wide chisel along the sides of the groove and tapped it lightly to
cut the fibers and prevent tearout while I cut the groove deeper. I then used a
quarter-inch chisel along the bottom of the groove to deepen it. Finally, I ran
a ball-end bit along the bottom using my rotary tool for the EL wire. That
worked&amp;hellip; less well, since it&amp;rsquo;s nigh-impossible to cut a straight line when the
tool itself is pulling to one side erratically. Fortunately, that part
shouldn&amp;rsquo;t be easily visible so it&amp;rsquo;s OK. Finally, I marked a line around both
sides of the blade to show where the grooves shuld end and filled in the gaps
with Bondo.&lt;/p&gt;

&lt;p&gt;The edge bevel on Penny&amp;rsquo;s Sword is quite complex, and doesn&amp;rsquo;t have the same
angle along the length of the sword. I cut as much on my scrollsaw as I could.
Unfortunately, the sword is too long to fit entirely on the saw. In the end, I
hat to cut most of the edge bevel with a couple of hand files and a rasp. That
actually worked quite well. It took hours and a lot of elbow grease, but
there&amp;rsquo;s something satisfying about patiently working with hand tools until the
part is Just Right. If you plan to do this at home, be sure you know how about
Draw Filing. If you don&amp;rsquo;t, the idea is that you hold one end of the file in
each hand, press the center against the work and push it forward and draw it
back. I&amp;rsquo;ve found this technique to be much faster and more controllable than
filing along the length of the file using a sawing motion.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-half-blade.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Once that was done, I spread some Bondo on some of the areas where I&amp;rsquo;d filed
too far and sealed the MDF with cyanoacrylate. Thin CA is best for this, as it
soaks deeper into the MDF, but my bottle of thin CA was so old that it turned
into thick CA all on its own. Regardless of the viscosity though, when the CA
hardens you&amp;rsquo;re left with a rough but hard and nicely sandable surface which
won&amp;rsquo;t soak up paint the way unsealed MDF does. It&amp;rsquo;s even wet-sandable, if done
carefully.&lt;/p&gt;

&lt;p&gt;With that, plus some more sanding and spot-putty work, the blade was ready for
primer.&lt;/p&gt;

&lt;h2 id=&#34;blade-details&#34;&gt;Blade Details&lt;/h2&gt;

&lt;p&gt;To make the half-round rail along the spine of the blade, I cut a piece of &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;&amp;rdquo;
dowel down the middle very carefully on my scroll saw, then cleaned it up by
rubbing the flat side of the now-half-round-ish dowel along a file. I glued
that down as straight as I could manage and cleaned up the seam with filler
primer, files and sanding twigs. For the larger half-cylindro-spherical (yeah,
I had to look that up) bit at the end, I cut a piece of &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&amp;rdquo; dowel in half and
cleaned it up as before, then used a sanding drum on my rotary tool to sculpt
the half-sphere part. This actually worked remarkably well. I couldn&amp;rsquo;t get it
to be quite round enough with just the rotary tool, but some work with a
sanding sponge and filler primer got it close enough. The inner corners between
the two parts and the spine of the blade are hard to reach so they&amp;rsquo;re not as
clean as I&amp;rsquo;d like, but they&amp;rsquo;re probably good enough.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-spine.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;There are some additional details on either side of the blade, but those had to
wait. Those details are on top of the diffuser for the glowy sections on the
sides, which created an order-of-operations problem. I had to install the EL
wire and the diffuser before I could add those details, and then I had to paint
those detail bits and the rest of the blade after the diffuser was installed.
So I had to mask out the lens and try not to get any paint on it.&lt;/p&gt;

&lt;p&gt;There is also an oblong piece on either side of the blade where it meets the
guard. I intially tried cutting these out on my scroll saw and sanding them to
the right shape, but I couldn&amp;rsquo;t quite get it right so I ended up just
laser-cutting them at the makerspace instead.&lt;/p&gt;

&lt;h2 id=&#34;guard&#34;&gt;Guard&lt;/h2&gt;

&lt;p&gt;Oh boy. This thing gave me so much trouble. As I mentioned above, I don&amp;rsquo;t have
a lathe and wouldn&amp;rsquo;t know how to use one if I did. That means I really have two
options for making this piece. I could cut it on the CNC mill, or I could 3D
print it. I don&amp;rsquo;t really like either one (CNC milling is a hassle and 3D
printing is boring) but needs must. I haven&amp;rsquo;t had much experience on the CNC
mill at my local makerspace, and I&amp;rsquo;m proud to say that I&amp;rsquo;ve added a number of
shining new mistakes to that experience which I hope to not repeat.&lt;/p&gt;

&lt;p&gt;Because this part had to be cut on both sides, I needed to be able to flip over
the work piece without actually moving it relative to the bed of the CNC
machine. In this case, this meant drilling a couple of holes through the
material into the sacrificial board on the bed of the machine, into which I
could place pieces of dowel. In theory, I could then flip the material over,
make sure the dowels are seated in their holes in the sacrificial board, and
carry on cutting on the other side. In practice, standard drill bits combined
with the much higher RPMs of the mill caused nasty tearout. Another piece of
sacrificial material on top of the workpiece would probably have helped.&lt;/p&gt;

&lt;p&gt;This CNC machine doesn&amp;rsquo;t have a tool-changer, so I had to manually replace the
tool multiple times during the cut. To do that, you need to adjust the origin
for the height axis to reflect that the new tool is longer or shorter than the
old one. If you reset the other axes, though, it&amp;rsquo;s impossible to finish the
cut, and that&amp;rsquo;s exactly what I did the first time. The second time, my work
piece came loose and I was informed that I had the movement speed of the CNC
router set far too high. Since this CNC machine is someone&amp;rsquo;s home-brew DIY
project, it&amp;rsquo;s somewhat lacking in documentation. Fortunately nothing was
damaged except my MDF.&lt;/p&gt;

&lt;p&gt;Having wasted several hours, damaged a couple cutting tools and destroyed two
blocks of MDF, I decided to just print it instead. This actually worked, which
is nice. It took a lot of sanding, puttying, priming and repeating before it
looked smooth enough, but I did get there in the end. I even printed in the
&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&amp;rdquo; holes on either end to attach it to the rod inside the blade, though I had
to use a &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&amp;rdquo; rat tail file to open them up a bit.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-guard.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;The guard also has some other parts. First, some flat segments to turn the ring
into a complete guard, which I laser-cut from acrylic and then finessed a bit
with my files until they fit into the ring. Second, there are some sections
that are raised above the center of the guard and have a power-symbol design
that lights up. Those were also laser-cut from MDF and acrylic. All of these
small MDF pieces were filleted with a sanding sponge, sealed with CA and
primed.&lt;/p&gt;

&lt;h2 id=&#34;hilt&#34;&gt;Hilt&lt;/h2&gt;

&lt;p&gt;Compared to all of that, the hilt was actually quite easy. I cut a couple of
sections of dowel to about twice the necessary length and took them to the
makerspace. After some failed experiments with the drill press, I asked a
couple of the guys there to help me with using the lathe to drill along the
center of the dowel. I&amp;rsquo;ll be honest - they did the work for me (thanks Al and
Scott!). Then I just cut the oversized dowel in half and had two hilt-sized
bits of wood which fit nicely on the &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;4&lt;/sub&gt;&amp;rdquo; rod extending from the blade. One
real one and a backup in case I messed up the first one. Helpful tip - always
make spares.&lt;/p&gt;

&lt;p&gt;I had planned to try to use a spokeshave to cut the round dowel, but the
spokeshave was too dull to cut with when it arrived. I really ought to learn
how to sharpen blades. For now, though, I just clamped the dowel down in my
vice and went at it with my files and a sanding sponge. I&amp;rsquo;ve yet to find a more
versatile tool than my cheap set of hand files from Home Depot.&lt;/p&gt;

&lt;p&gt;The hilt has a raised section on either end. Initially, I thought I&amp;rsquo;d heat up
some 1mm styrene, wrap it around and glue it in place. This didn&amp;rsquo;t work
(probably because I was trying to use a hair dryer and hot water. Maybe a heat
gun would have worked). After puzzling about it for a while, I came up with a
better idea. I cut a strip of thinner styrene which was flexible on its own.
Then I wrapped that around the hilt multiple times, using styrene cement to
glue each layer to the one beneath it like a roll of tape. This left an edge
where the styrene strip ended, but some filing and sanding blended that in
nicely. The styrene cement bonded the styrene to itself but not to the wood, so
I mixed a bit of epoxy and glued the two styrene end-caps to the dowel.&lt;/p&gt;

&lt;p&gt;This all worked pretty well, but the two end-caps weren&amp;rsquo;t quite flush with the
sides of the hilt. I fixed that by scooping some baking soda into the gaps,
tapping it a bit to get it inside, and then scraping away the excess. With the
baking soda filling the gap, I dripped some thin CA (by this point I&amp;rsquo;d bought
a new bottle) inside. Baking soda causes CA to harden instantly and take up
more space than CA normally does, so this filled in the gaps nicely. A bit more
work with some needle files and sanding twigs to clean it up and it was ready to
go.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-hilt.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is getting quite long, so I&amp;rsquo;m going to wrap up here. Almost all of the
parts are shaped, refined and primed. In &lt;a href=&#34;https://bheisler.github.io/post/pennys-sword-rwby-part2&#34;&gt;part 2&lt;/a&gt;, I&amp;rsquo;ll explain how I painted,
wired and finished the sword.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s what all of the pieces look like so far:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://bheisler.github.io/static/pennys-sword-parts.jpg&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h2 id=&#34;tools-and-materials&#34;&gt;Tools and Materials&lt;/h2&gt;

&lt;p&gt;Here&amp;rsquo;s a short list of some of the tools and materials I used in this post:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2ylNm5c&#34;&gt;Rustoleum Filler Primer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2xFPByh&#34;&gt;Plastruct Bondene&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bondo &lt;a href=&#34;http://amzn.to/2znGzrT&#34;&gt;Spot Putty&lt;/a&gt; and &lt;a href=&#34;http://amzn.to/2znHgRS&#34;&gt;Body Filler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2yokPO2&#34;&gt;Needle Files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2ymxzmS&#34;&gt;Epoxy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Experiments In NES JIT Compilation</title>
      <link>https://bheisler.github.io/post/experiments-in-nes-jit-compilation/</link>
      <pubDate>Sun, 20 Aug 2017 11:35:37 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/experiments-in-nes-jit-compilation/</guid>
      <description>

&lt;p&gt;Inspired by the always-incredible work on &lt;a href=&#34;https://dolphin-emu.org/&#34;&gt;Dolphin&lt;/a&gt;,
I decided to write myself an &lt;a href=&#34;https://github.com/bheisler/Corrosion&#34;&gt;NES emulator&lt;/a&gt;
called Corrosion a couple years ago. I managed to get it working well enough to
play basic games, and then put the project aside. This post is not about the
emulator itself, but rather the JIT compiler I added to it last year and the
upgrades to said JIT compiler I&amp;rsquo;ve made over the past few weeks.&lt;/p&gt;

&lt;p&gt;Having read that, you might be wondering &amp;ldquo;Why would anybody write a JIT compiler
for the NES?&amp;rdquo; Indeed, it&amp;rsquo;s a reasonable question. Unlike newer consoles, it&amp;rsquo;s
quite feasible to emulate the NES&amp;rsquo;s modified 6502 CPU at full speed with a
simple interpreter. As with most of the projects I write about here, I wanted
to know how they work, so I built one. Having done so, I can say that I would
not recommend JIT compilation for production-quality NES emulators except in
severely resource-constrained environments. However, I would strongly recommend
this project for anyone who wants to learn more about JIT compilers, as it&amp;rsquo;s
complex enough to be challenging but simple enough to be manageable.&lt;/p&gt;

&lt;p&gt;This is more of a post-mortem article covering the design of my JIT compiler,
the pitfalls I ran into and the mistakes I made in construction and what I&amp;rsquo;ve
learned from the process. It is not a tutorial on how to write your own JIT
compiler, though there are some links that cover that in more detail at the end.
The emulator is written in Rust, but you don&amp;rsquo;t need to know Rust to follow along.
Most of the concepts will map to other low-level languages like C or C++. An
understanding of x64 assembly would be helpful, but again, not required - I
didn&amp;rsquo;t know much assembly starting this project, and even now my assembly is
pretty weak.&lt;/p&gt;

&lt;h2 id=&#34;basics-of-jit-compilation&#34;&gt;Basics of JIT Compilation&lt;/h2&gt;

&lt;p&gt;Just to make sure everyone&amp;rsquo;s on the same page, a quick interlude on how JIT
compilers work at a high level. If you&amp;rsquo;re familiar with this already, feel free
to skip ahead.&lt;/p&gt;

&lt;p&gt;Broadly speaking, a JIT (or just-in-time) compiler is a piece of code that
translates some kind of program code into machine instructions for the host CPU.
The difference between a JIT compiler and a regular compiler is that a JIT
compiler performs this translation at runtime (hence just-in-time) rather than
compiling the code and saving a binary for later execution.
For emulation, the original program code is typically the binary machine code
that was intended for the emulated CPU (in this case the NES&amp;rsquo; 6502 CPU). However,
JIT compilers are used for many other kinds of programs. Examples include the
JIT compilers used by modern browsers to run Javascript, the Hotspot compiler
in the JVM and dynamic language runtimes like PyPy and LuaJIT.&lt;/p&gt;

&lt;p&gt;JIT compilers are used primarily to speed up execution. A standard interpreter
must fetch, decode and execute instructions one at a time. Even in a relatively
fast language like Rust or C, this incurs some overhead. A JIT compiler, on the
other hand, can be run once and emit a blob of machine code which executes an
entire emulated function (or more) in one sequence of instructions. Eliminating
that overhead often greatly improves execution speed. However, since the
compilation is done at runtime, care must be taken that the JIT compiler itself
doesn&amp;rsquo;t run slowly enough to cause performance problems, where an ahead-of-time
(AOT) compiler can spend much more time optimizing the code it generates.&lt;/p&gt;

&lt;p&gt;A JIT compiler typically parses some chunk of code, performs any analysis
it needs to, and then generates binary machine code for the host CPU into a
code buffer. Modern OS&amp;rsquo;s require these code buffers to be marked as read-only
and executable before they can be executed, but once this is done the generated
code can be executed by jumping the host processor to the beginning of the buffer
just like any normal function. Some more sophisticated JIT compilers will
translate the source language into some intermediate in-memory representation
for further processing before emitting the final machine code.&lt;/p&gt;

&lt;p&gt;As a simple example, consider the following 6502 code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LDA $1A  // Load byte from RAM at 0x001A into A register
ADC #$20 // Add 0x20 to the A register
STA $1A  // Store A register into RAM at 0x001A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This might be translated into the following (simplified) x64 code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MOV r9b, [rdx + 1Ah] // Load byte from RAM array pointed to by rdx into r9b
ADC r9b, 20h         // Add 0x20 to r9b, which represents the A register
MOV [rdx + 1Ah], r9b // Store the result back into the RAM array at 0x001A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that I&amp;rsquo;ve omitted things like processor flags and interrupts from this
example.&lt;/p&gt;

&lt;h2 id=&#34;design-of-corrosion-s-jit&#34;&gt;Design of Corrosion&amp;rsquo;s JIT&lt;/h2&gt;

&lt;p&gt;Corrosion has a relatively simplistic JIT compiler. It has no intermediate
representation or register allocator, which might be found in more sophisticated
JIT compilers - Dolphin&amp;rsquo;s PPC JIT has a register allocator, while David Sharp&amp;rsquo;s
Tarmac ARM emulator features an IR called Armlets (see links at the end).
Since machine code is typically a binary format too complex for humans to write
directly, most JIT compilers also devote much code to translating some
assembly-like syntax or DSL used by the developers into the bytes that are given
to the host CPU. Fortunately for me, there is an extremely useful compiler plugin
by CensoredUsername called &lt;a href=&#34;https://github.com/CensoredUsername/dynasm-rs&#34;&gt;dynasm-rs&lt;/a&gt;
which can parse an Intel-assembly-like syntax and perform most of the assembly
at compile time. I would recommend any Rust-based JIT compiler author should
check out this plugin; I&amp;rsquo;ve found it to work well, with no bugs to speak of and
CensoredUsername was very helpful about answering my silly questions when I asked.
The only limitation is that it currently only supports the x64 instruction set,
though x86 support is planned. For those who prefer C/C++, there is a similar
tool called &lt;a href=&#34;https://luajit.org/dynasm_features.html&#34;&gt;DynASM&lt;/a&gt;, though I can&amp;rsquo;t
comment on that as I&amp;rsquo;ve never used it myself.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/a949bf7d08573e4529b4a9e2fd10f5e6.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The entry point to the JIT compiler in Corrosion is the
&lt;a href=&#34;https://github.com/bheisler/Corrosion/blob/develop/src/cpu/dispatcher.rs&#34;&gt;dispatcher module&lt;/a&gt;.
When the CPU interpreter detects that it&amp;rsquo;s executing an address from the ROM,
it makes a call to the dispatcher to compile (if necessary) and execute the
relevant block of code. The dispatcher is responsible for managing the cache
of generated code blocks and calling to the JIT compiler to generate more code
when necessary.&lt;/p&gt;

&lt;p&gt;If the dispatcher doesn&amp;rsquo;t have an existing generated code block for a particular
location in ROM, the &lt;a href=&#34;https://github.com/bheisler/Corrosion/blob/develop/src/cpu/nes_analyst.rs&#34;&gt;nes_analyst module&lt;/a&gt;
is used to collect information about the code to be compiled. The primary
responsibility of nes_analyst is to determine where the end of the current
function is and collect information about the instructions it contains.
This is done using a very simplistic algorithm that I copied from Dolphin. It
decodes instructions until it finds the first unconditional exit point (eg.
returns, jumps or calls to other functions). To ignore the conditional exit
points, it tracks the target address of the farthest forward-facing branch it&amp;rsquo;s
seen; any exit point before that is conditional. This approach does occasionally
overestimate the length of the actual function, but it&amp;rsquo;s simple and fast.
The nes_analyst module is also responsible for identifying which instructions
are the targets of branches and which instructions change or use which processor
flags, which is used later in the compilation process. Decoding opcodes is done
using the &lt;code&gt;decode_opcode!&lt;/code&gt; macro which expands to a giant match structure that
calls the appropriate functions. &lt;code&gt;decode_opcode!&lt;/code&gt; has handling for the various
addressing modes which we don&amp;rsquo;t really need here, so there is some clutter,
but it works well enough.&lt;/p&gt;

&lt;p&gt;As mentioned earlier, Corrosion doesn&amp;rsquo;t have a register allocator. It&amp;rsquo;s quite
common for emulated CPU&amp;rsquo;s to have more registers than the host CPU, especially
since many JIT compilers run on the relatively register-light x86
and x64 instruction sets. As a result, they need to do the extra step of
determining which emulated registers should be represented by host registers
and which should be stored in memory at any given point in the code. Conveniently,
the NES&amp;rsquo;s 6502 CPU has even fewer registers than x64 does, which means we can
statically assign one x64 register to represent each 6502 register and have a
few left over to store things like the pointers to the Rust CPU structure and
the array which stores the emulated RAM, as well as a few more for general-purpose
scratch memory.&lt;/p&gt;

&lt;p&gt;Most 6502 instructions come in various different flavors called addressing modes,
which control where they take some of their data from. Take the CPX (ComPare X)
instruction as an example. This instruction compares the value in the X register
to a one-byte operand, setting the N (sign), Z (zero), and C (carry) flags.
If the opcode is 0xE0, the operand is a one-byte immediate value stored
right after the opcode. If the opcode is 0xE4, the next byte is instead
zero-extended to 16 bits and used as an address into RAM. This mode is called
the zero-page mode, and it can only access the first 255 bytes of RAM, which are
called the Zero Page. The byte at the selected location is used for the
comparison. Finally, if the opcode is 0xEC, the next two bytes (little-endian)
are used as an absolute address into memory and whichever byte they select is used.
If you&amp;rsquo;re wondering, zero page instructions are one byte smaller and slightly
faster than absolute instructions, which matters when you have a 64k address
space and 1.34MHz CPU.&lt;/p&gt;

&lt;p&gt;There are a number of other addressing modes, but this should suffice to explain
the concept. I could have written hand-tuned machine code for all 255 possible
opcodes, but I&amp;rsquo;m a lazy programmer, so instead I wrote a collection of routines
that generate code to move the appropriate byte into one of my scratch registers
(r8). That way, I can call the routine appropriate for the addressing mode to load
the operand into r8, then define the instruction code to take it from there.
Likewise, when writing to memory, I can move the value to be written into r8
and call a routine to generate the instructions to transfer that value into the
appropriate location in memory. It&amp;rsquo;s slightly less efficient at runtime because
I have to move data through an intermediate register instead of using it
directly, but it saved a lot of my time.&lt;/p&gt;

&lt;p&gt;Slight aside - I was a bit surprised by how small the difference is between
writing code to implement something and writing code that generates a program
to implement something. I&amp;rsquo;ll use CPX as an example again - this is some code
from an earlier version of the JIT:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/eebebbacefda3c626f597a6c865805dd.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;If I were actually writing this in assembly, this reads like pretty much how
I&amp;rsquo;d do it - call the function for the appropriate addressing mode to load the
operand, do some branching to set or clear the carry flag, compare the operand
against the X register and call some functions to update the sign and zero
flags. In fact, that&amp;rsquo;s exactly how the interpreter handles this instruction.
Instead, I&amp;rsquo;m calling a function to generate the code to load the operand,
generating code to do the comparison and update the flags, etc. Despite that
extra layer of indirection, though, it reads pretty much the same. Because
of this, implementing all of the instructions was as straightforward as
translating my Rust code into assembly. I&amp;rsquo;m not actually that good with
assembly, so my code will probably make experienced assembly programmers cry.
Still, it does the job. With that said, I would be interested in ideas for
making it better if anyone would care to share links or suggestions.&lt;/p&gt;

&lt;h2 id=&#34;enhancements&#34;&gt;Enhancements&lt;/h2&gt;

&lt;p&gt;That brings me up to the present, more or less. Over the past few weeks I&amp;rsquo;ve
been working on some &amp;lsquo;optimizations&amp;rsquo; to the JIT compiler. I write that in quotes
because for the most part I can&amp;rsquo;t actually detect any measurable change in
execution speed for these, but they were somewhat interesting to implement.&lt;/p&gt;

&lt;p&gt;The first such enhancement that I added was redundant flag elimination. This was
actually really easy and I probably should have done it from the start. The idea
here is that a good chunk of the code emitted by a JIT compiler (at least for
emulators) does nothing but implement the various flag behaviors of the emulated
CPU (eg. setting the overflow flag when an addition overflows). To some extent,
a clever JIT compiler author can exploit similar flags in the host CPU to
accomplish this with fewer instructions, but it&amp;rsquo;s still there. If you look at
&lt;a href=&#34;http://www.oxyron.de/html/opcodes02.html&#34;&gt;documents detailing the 6502&amp;rsquo;s instruction set&lt;/a&gt;,
you&amp;rsquo;ll quickly see that many instructions change the flags in some way,
but very few instructions use them. What this means is that a typical program
will overwrite processor flags far more often than they&amp;rsquo;re actually used.
Interpreters sometimes take advantage of this by not storing the flags at all,
and instead storing enough data to calculate the flags and then evaluating them
lazily when needed. A JIT compiler, however, can go one step further and analyze
every instruction to see if that flag value will be used before it&amp;rsquo;s overwritten
by another instruction. If not, it doesn&amp;rsquo;t emit the machine code to update the
flag.&lt;/p&gt;

&lt;p&gt;The way I implemented this is to have nes_analyst keep track of the last
instruction to change each flag while it&amp;rsquo;s stepping through a function. Then
when it hits an instruction that uses a flag, it looks up the InstructionAnalysis
structure for the last instruction to set the flag, which contains a set of
booleans indicating whether each flag will be used. Since we now know that that
instruction&amp;rsquo;s flag will be used and not overwritten, we set the appropriate
boolean to true, signaling the JIT compiler to emit code to update that flag
later on.&lt;/p&gt;

&lt;p&gt;There are a few pitfalls with this approach. For instance, if a branch is taken
or if execution hits a jump instruction, we can&amp;rsquo;t know if the code it jumps to
will rely on this flag. If so, this optimization could break. A more
sophisticated analysis could probably detect that, for at least some cases.
This one-pass algorithm can&amp;rsquo;t, so to be on the safe side it assumes that jump
and branch instructions use all of the flags. Likewise, when an interrupt
occurs, the NES pushes the flags and the return address on the stack. Since an
interrupt can occur at any time, there&amp;rsquo;s no way to be sure that the flags byte
it pushes on the stack will be correct. I don&amp;rsquo;t have a solution to this except
to assume that no game will break because of the exact value of the flags byte
on the stack. This seems like a safe assumption. Since interrupts can happen at
any time, it would be difficult to know what the flags should have looked like
when the interrupt happened. Something to be aware of, though.&lt;/p&gt;

&lt;p&gt;The initial version of my JIT compiler emitted a fixed series of instructions
(a function prologue) at the beginning of every compiled block which rearranged
the arguments from the win64 calling convention and loaded all of the NES
register values out of memory into the designated x64 registers. Then, at every
possible exit point from the block, it would emit some code (the epilogue) to
do the reverse; store the register values back in memory and return control
back to the interpreter. This means we can&amp;rsquo;t just jump to the middle of a
compiled function - we&amp;rsquo;ll skip over the prologue and crash. Therefore, if some
other code tries to jump into the middle of a function, we need to compile that
function suffix as a complete function of its own, with its own prologue and
epologues. Also, these duplicate prologues and epilogues take up space in the
instruction cache, which could reduce performance.&lt;/p&gt;

&lt;p&gt;Instead, I&amp;rsquo;ve changed it to use a trampoline; this is an ordinary Rust function
taking the pointer to the compiled code to jump to as well as the pointers to
the CPU structure and the RAM array. It contains an &lt;code&gt;asm!&lt;/code&gt; macro which defines
the assembly instructions to load the registers from memory, call the compiled
block and then store the updated registers back into memory. Since we now only
have one global &amp;lsquo;prologue/epilogue&amp;rsquo; shared between all compiled code blocks, we
can then call directly into the middle of an existing block with no trouble.&lt;/p&gt;

&lt;p&gt;Another problem with the prologue/epilogue design was that compiled blocks
couldn&amp;rsquo;t easily call each other; the JIT would have to store everything back in
memory to prepare for the prologue to be run again, or know how to jump past
the prologue or something else complicated. With a trampoline-based design,
it&amp;rsquo;s easy to jump to another block - everything&amp;rsquo;s already loaded into the
appropriate registers, so you can just jump the host processor to the beginning
of the target block. One wrinkle is that you need to be careful not to link
together blocks from different banks of ROM, since one bank could be switched
out and now your code is jumping to the wrong place.&lt;/p&gt;

&lt;h2 id=&#34;challenges&#34;&gt;Challenges&lt;/h2&gt;

&lt;p&gt;Speaking of that trampoline function, I did run into some difficulty implementing
it. The trampoline function needs to transfer values from a struct in memory
to and from registers. It takes a pointer to a CPU struct as an argument, but
that alone isn&amp;rsquo;t enough; Rust can rearrange and pad the fields however it likes,
so I needed a way to get the offset of each field from the pointer to the CPU.
C/C++ programmers can use the offsetof macro, but Rust has no official way to
calculate the offset of a field within a structure. The layout of Rust structures
isn&amp;rsquo;t even guaranteed to be the same from release to release - in fact, it &lt;a href=&#34;http://camlorn.net/posts/April%202017/rust-struct-field-reordering.html&#34;&gt;was
changed&lt;/a&gt;
just a few months ago in version 1.18.  I could have marked the CPU struct with
&lt;code&gt;repr(C)&lt;/code&gt; to force it to use the C layout and used hard-coded offsets, but that
felt inelegant. I would have needed to update the offsets every time I modified
the CPU struct, for one thing. Instead, I found a macro online that can calculate
the offset of any field in a structure.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/b21c9bfc07ee4c1afac2e96ef55dfffd.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;This works by casting 0 (NULL) to a raw pointer to a &lt;code&gt;$ty&lt;/code&gt; structure,
dereferencing it, taking a reference to the field and casting that pointer back
to a usize. As far as I can tell, this is actually safe and should be entirely
evaluated at compile time, but it still needs to be wrapped in an unsafe block
anyway. Use at your own risk, etc. etc. It&amp;rsquo;s pretty easy to add more macros to
calculate offsets with multiple levels of nesting - see &lt;code&gt;offset_of_2&lt;/code&gt; in
&lt;code&gt;x86_64_compiler/mod.rs&lt;/code&gt; for an example. One drawback of this is that it can&amp;rsquo;t
be used for static values - it&amp;rsquo;s forbidden to dereference null pointers when
initializing static values, even with unsafe. Because of that, I didn&amp;rsquo;t think
it would work with the &lt;code&gt;asm!&lt;/code&gt; macro&amp;rsquo;s &lt;code&gt;n&lt;/code&gt; value constraint (meaning constant
integer) but it totally does. Still, it&amp;rsquo;d be really nice if this was something
Rust supported out of the box.&lt;/p&gt;

&lt;p&gt;Another challenge I ran into while implementing this is dealing with some
quirks of the win64 calling convention. Rust, you see, does not have a defined
calling convention, so there&amp;rsquo;s no reliable way to call directly into Rust code
from assembly. Instead, you expose a function marked &lt;code&gt;extern &amp;quot;win64&amp;quot;&lt;/code&gt; or
similar which then calls the function you actually want. This way, you set up
your code to be compatible with the chosen calling convention - pushing
caller-saved registers on the stack, placing arguments in the right registers -
and leave Rust to handle the translation to its own internal calling
convention. The win64 convention is one of two 64-bit calling conventions
supported - the other one, sysv64, is still experimental and requires a special
feature flag even on nightly. The JIT compiler needs to call back into Rust
code to handle things like reading and writing memory-mapped devices like the
PPU or the controllers. Unfortunately, win64 is slightly difficult to work
with. It requires that the stack pointer be 16-byte aligned at the entry to
every function, and that the caller provide a 32-byte empty space on the stack
before the return address for the callee to use as scratch space. Failure to do
this correctly causes hard-to-debug segfaults. In my code, I don&amp;rsquo;t have many
places where I call back to Rust code, and the generated code doesn&amp;rsquo;t use the
stack very much, so I deal with this by just hard-coding the number of bytes of
space to leave on the stack. It&amp;rsquo;s not ideal (if I had more complex requirements
I might add a trampoline_to_win64 function to match trampoline_to_nes), but
other JIT compiler authors should be aware of it.&lt;/p&gt;

&lt;p&gt;Next up, debugging. Debugging a JIT compiler sucks even more than debugging an
interpreter. Debugging tools largely just don&amp;rsquo;t handle runtime-generated
machine code. Visual Studio, despite having a quite competent disassembly view,
just will not step into a generated code block. GDB&amp;rsquo;s disassembly view will at
least display the generated code and let you scroll downwards through it, but
not back upwards (I guess because it doesn&amp;rsquo;t know which byte to start
disasembling from, but it could at least allow you to scroll back up to the
program counter). GDB also fails to insert breakpoints into generated code
blocks even when you give it the address of the instruction to break at. GDB
has some sort of interface for exposing debugging info for JIT-compiled code,
but I wasn&amp;rsquo;t able to make much sense of it. Apparently it relies on the JIT
compiler generating and emitting a complete ELF table in memory for the
generated code, which sounds like a lot of hassle. Anyway, in the absence of a
debugger, good old println-debugging is your best friend. This is complicated
by the fact that you have to insert your debug output into the generated code
at runtime, but I&amp;rsquo;d strongly suggest you find a way. I wish I had done this
earlier, it would have saved me a ton of debugging time.&lt;/p&gt;

&lt;p&gt;Handling interrupts also proved to be something of a challenge. The NES has
very tight synchronization between the CPU and the other hardware, which
includes interrupts. I had hoped there would be some clever way to implement
interrupts without just checking if there had been an interrupt before every
emulated instruction, but I couldn&amp;rsquo;t find one. This is part of why the
duplicate epilogues were a problem, in fact; every emulated instruction was
preceded by an implicit exit point, so there were a lot of redundant epilogues.
The best I could come up with was to store a cycle count representing when the
next interrupt would occur and then compare that against the actual cycle count
before every instruction. This sort of works, because the hardware interrupts
of the NES are entirely predictable, but it probably wouldn&amp;rsquo;t work for other
systems. On the other hand, other systems probably don&amp;rsquo;t require such tight
timing for the interrupts, so if you&amp;rsquo;re writing a JIT you might be able to get
away with only checking for interrupts once every 10 emulated instructions or
something.&lt;/p&gt;

&lt;p&gt;As I mentioned in my post on &lt;a href=&#34;https://bheisler.github.io/post/nes-rom-parser-with-nom/&#34;&gt;parsing iNES ROM headers&lt;/a&gt;,
the NES only has 32k of address space mapped to the ROM. Some games take up
more than a megabyte of ROM space, so NES cartridges incorporate circuitry so
that the game can map banks of the ROM in and out of the address space.
Implementing the bankswitching logic is one thing, but this allows for the
possibility of self-modifying code even if you only use the JIT compiler when
executing from ROM. There are all sorts of wacky corner cases this enables -
what if the bank you&amp;rsquo;re executing is switched out between instructions? What if
half of a block is on one bank and the other is on the next bank, then the
second half gets switched out? If you then execute a generated code block that
compiled in the instructions from the original bank, the game will probably
break. You could even have a multi-byte instruction on a bank boundary, such
that the last byte of the instruction depends on which bank is mapped in. I&amp;rsquo;ll
be honest, I didn&amp;rsquo;t solve this problem. Corrosion just assumes that no game
will do strange stuff like this. Initially, I took a much more conservative
approach and deleted all of the compiled code for a bank whenever it was
switched out. This was a mistake; games like Legend of Zelda bankswitch
frequently enough that the emulator was constantly recompiling sections of code
that it had already compiled before. Major respect for the developers of other
JIT-based emulators - dealing with arbitrary self-modifying code, especially in
situations where you have an instruction cache and/or pipelining, must be a
nightmare.&lt;/p&gt;

&lt;h2 id=&#34;other-resources-conclusion&#34;&gt;Other resources &amp;amp; conclusion&lt;/h2&gt;

&lt;p&gt;Well, that&amp;rsquo;s about it from me. This was a bit more stream-of-consciousness than
my posts usually are, since I was writing about something I made a while ago.
I normally write my posts concurrent with working on the projects they cover.
I hope you found it interesting and/or educational. I&amp;rsquo;ll leave you with some
links to other resources that I used or wish that I&amp;rsquo;d known about when I was
building this thing.&lt;/p&gt;

&lt;p&gt;First off, Eli Bendersky&amp;rsquo;s Adventures In JIT Compilation series
(&lt;a href=&#34;http://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/&#34;&gt;Part 1&lt;/a&gt;,
&lt;a href=&#34;http://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-2-an-x64-jit/&#34;&gt;Part 2&lt;/a&gt;,
&lt;a href=&#34;http://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-3-llvm/&#34;&gt;Part 3&lt;/a&gt;,
&lt;a href=&#34;http://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-4-in-python/&#34;&gt;Part 4&lt;/a&gt;)
is an excellent introduction to the low-level details of implementing an
interpreter and a series of JITs for Brainfuck, including different ways of
generating machine code, intermediate representations and so on.&lt;/p&gt;

&lt;p&gt;Second, David Sharp&amp;rsquo;s &lt;a href=&#34;http://www.davidsharp.com/tarmac/tarmacreport.pdf&#34;&gt;report on Tarmac&lt;/a&gt;,
an optimizing JIT compiler for ARM emulation. It&amp;rsquo;s over a hundred pages long,
but this is an excellent overview of JIT compilation techniques as well as a
detailed explanation of how Tarmac works. Sharp gives a good explanation (often
including diagrams and/or examples) of common approaches to various problems in
emulation, even if Tarmac itself doesn&amp;rsquo;t use them. If nothing else, read it to
learn about terminology you can plug into a search engine to find out more.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re interested in NES emulation in particular, &lt;a href=&#34;http://wiki.nesdev.com/w/index.php/Nesdev_Wiki&#34;&gt;the NESdev wiki&lt;/a&gt; is the premiere source of information for aspiring emulator developers and
homebrew ROM authors. This wiki and the resources it links to (including
&lt;a href=&#34;http://forums.nesdev.com/&#34;&gt;the forums&lt;/a&gt;,
&lt;a href=&#34;https://wiki.nesdev.com/w/index.php/Emulator_tests&#34;&gt;test ROMs&lt;/a&gt;, and lots
of documentation about the CPU/PPU/APU) provided all of the documentation I used
to build this emulator in the first place.&lt;/p&gt;

&lt;p&gt;Finally, Dolphin&amp;rsquo;s JIT doesn&amp;rsquo;t seem to have much documentation, so if you want
to find out more about it there are only two sources that I&amp;rsquo;ve found useful.
The &lt;a href=&#34;https://github.com/dolphin-emu/dolphin/tree/master/Source/Core/Core/PowerPC&#34;&gt;source code&lt;/a&gt;,
and &lt;a href=&#34;https://www.reddit.com/r/emulation/comments/2xq5ar/how_close_is_dolphin_to_being_cycle_accurate/cp318ka/&#34;&gt;this Reddit comment&lt;/a&gt;
by one of the developers giving a relatively high-level overview of how it all
works.&lt;/p&gt;

&lt;p&gt;This has been a fun project. I have some other stuff in the pipeline at the
moment, but I&amp;rsquo;d like to come back to this emulator at some point. Until next
time&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parsing NES ROM Headers with nom</title>
      <link>https://bheisler.github.io/post/nes-rom-parser-with-nom/</link>
      <pubDate>Sun, 30 Jul 2017 02:11:19 +0000</pubDate>
      
      <guid>https://bheisler.github.io/post/nes-rom-parser-with-nom/</guid>
      <description>

&lt;p&gt;Long, long ago (December 2015) I wanted to learn how emulators worked, so I
decided to write an &lt;a href=&#34;https://github.com/bheisler/Corrosion&#34;&gt;NES emulator&lt;/a&gt;.
Not only that, but I opted to write it in Rust, a language which I had never
used before. A crazy idea, to be certain, but once I was done I had indeed
learned a great deal about emulators, the NES, and Rust.&lt;/p&gt;

&lt;p&gt;Anyway, I&amp;rsquo;ve been working on that project again lately, doing some maintenance work
and upgrades. One of the things I did was rewrite the ROM parser using
&lt;a href=&#34;https://github.com/Geal/nom&#34;&gt;nom&lt;/a&gt;. The ROM parser was the first bit of Rust code
I&amp;rsquo;ve ever written, and it was not great, so I thought it was finally time to clean
it up a bit. This post is a short description of that process and my thoughts on
nom as a newcomer to this library. First, a detour to discuss the NES ROM format
- if you&amp;rsquo;re not interested in the fine details, you can skip ahead to the next
section.&lt;/p&gt;

&lt;h2 id=&#34;the-ines-header&#34;&gt;The iNES Header&lt;/h2&gt;

&lt;p&gt;Nearly all NES ROM files are in one of two formats. There&amp;rsquo;s the
&lt;a href=&#34;https://wiki.nesdev.com/w/index.php/INES&#34;&gt;iNES&lt;/a&gt; format, or a later extension
called &lt;a href=&#34;https://wiki.nesdev.com/w/index.php/NES_2.0&#34;&gt;NES 2.0&lt;/a&gt;. My existing parser
only supports iNES, and that&amp;rsquo;s all the new parser will support as well. I haven&amp;rsquo;t
come across many ROM&amp;rsquo;s in NES 2.0 format yet, so I haven&amp;rsquo;t needed to add support
for it.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start digging into the iNES header and I&amp;rsquo;ll explain what everything is as
we go. First, we have a four-byte magic number - the ASCII letters &amp;lsquo;NES&amp;rsquo; followed
by 0x1A - the DOS end-of-file character. After that is one byte holding the length
of the PRG ROM data in 16kB blocks and one byte for the length of CHR ROM in 8kB blocks.
NES cartridges contain PRG ROM and CHR ROM. PRG (program) ROM holds the
assembled program code and associated data for the game. It&amp;rsquo;s available in the
main CPU memory map by reading 0x4020 to 0xFFFF, though many cartridges only
support reading PRG ROM at addresses above 0x8000. CHR (character) ROM holds the
graphical data for the game and is only indirectly accessible to the CPU.
CHR ROM is used instead by the PPU (Picture Processing Unit). Some cartridges
have no CHR ROM and instead use CHR RAM, transferring the graphical data
to the CHR RAM at runtime.&lt;/p&gt;

&lt;p&gt;After those two bytes are two more bytes of flags. These include various bits
of information about the hardware of the cartridge (eg. whether or not the
cartridge has battery-backed RAM for saving your game). These flag bytes also
contain the mapper ID for the game. Mappers are one of the more&amp;hellip; interesting&amp;hellip;
aspects of NES emulation. As I mentioned before, the PRG ROM is typically
accessible from 0x8000 to 0xFFFF - a window of 32kB. 32kB is not nearly large
enough for most NES games (some of which have as much as 1MB of PRG ROM alone). To
deal with this, cartridges contain circuit boards called mappers which map
pages of the ROM in and out of the address space. Different games, and especially
games by different manufacturers, often have wildly different mappers. The
emulator must emulate the mapper as well, so the header contains one byte
(split into two 4-bit pieces for historical reasons) containing the mapper ID.&lt;/p&gt;

&lt;p&gt;After the first two flag bytes is another page-count byte, this time for PRG
RAM (the battery-backed save RAM in games like Legend of Zelda) and another
flags byte. Finally, we have six reserved bytes, which are not used by iNES but
are used by NES 2.0.&lt;/p&gt;

&lt;p&gt;To recap:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;4-byte magic number&lt;/li&gt;
&lt;li&gt;PRG ROM page count&lt;/li&gt;
&lt;li&gt;CHR ROM page count&lt;/li&gt;
&lt;li&gt;Lower half of mapper number &amp;amp; flags&lt;/li&gt;
&lt;li&gt;Upper half of mapper number &amp;amp; flags&lt;/li&gt;
&lt;li&gt;More flags&lt;/li&gt;
&lt;li&gt;Six bytes of zeroes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Following this header is an optional 512-byte trainer (extra program code added
by some ROM-ripping devices), and the actual PRG and CHR ROM data. Now that we know
what we&amp;rsquo;re parsing, let&amp;rsquo;s take a look at nom.&lt;/p&gt;

&lt;h2 id=&#34;nom&#34;&gt;nom&lt;/h2&gt;

&lt;p&gt;The way parsing works in nom is you use the do_parse! macro to define your
parser, and a number of other functions and macros to define the structure of
your data. These macros and functions collectively generate some Rust code which
parses that data and returns one of three possible results - Done (containing any
remaining, unparsed data and the resulting value), Incomplete (meaning more
data is needed) or Error (meaning the data is invalid or otherwise couldn&amp;rsquo;t
be parsed). The use of macros for this is a rather clever idea, though not
without downsides.&lt;/p&gt;

&lt;p&gt;One of those downsides is that the compiler can&amp;rsquo;t really help you when you
make a mistake. For instance, it took me longer than I&amp;rsquo;d like to admit to get
the following code to compile before I realized that I had forgotten to pass
the input to the do_parse macro.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2fae3b00eedcb80a1a109e622a55f74f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Once I got going though, it was pretty smooth sailing and extremely fast to
parse out the rest of the header and construct my Rom structure. The tag!
macro takes a given sequence of bytes and reads that sequence from the input.
be_u8 (the &amp;lsquo;be&amp;rsquo; means big-endian) is a one-byte unsigned integer. Then we have
the cond! macro, which applies a given parser if some condition is true, and
finally the take! macro, which consumes a given number of bytes and returns
them as a slice.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/a39a0fdd5b1741ce7982849febe914c8.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Since my code doesn&amp;rsquo;t support the NES 2.0 extension, I wanted to detect if a ROM
was using that format and return an error. This is where I started to run into
trouble; I couldn&amp;rsquo;t find an obvious way to conditionally return an error.
I ended up working around it by using the call! macro to call a function I wrote
which would return an error if the ROM was in NES 2.0 format. This was somewhat
surprising to me; this seems like it would be a common problem.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/68c917c9f44934dd848b0efa61e7dbdd.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;At this point, I had a working parser, but I decided to take the opportunity to
rework my code a bit as well. Previously, I simply stored the flag bytes in the
Rom structure and left it to other code to mask out the individual flags, as well
as the two 4-bit pieces of the mapper ID. nom can parse individual bits out of
the input as well, so I started with separating out the mapper ID from the rest
of the flag bytes.&lt;/p&gt;

&lt;p&gt;nom overall could use some work on its documentation, but using the bit-indexing
is particularly opaque. I had to look up a cached version of an old blog post
(&lt;a href=&#34;https://webcache.googleusercontent.com/search?q=cache:4CNayFlPRicJ:siciarz.net/24-days-rust-nom-part-2/+&amp;amp;cd=1&amp;amp;hl=en&amp;amp;ct=clnk&amp;amp;gl=ca&#34;&gt;link&lt;/a&gt;)
to find out how to do it. To spare you the same trouble, here&amp;rsquo;s a quick overview.&lt;/p&gt;

&lt;p&gt;The bits! macro takes a bit-stream parser (eg. take_bits!) or a type-agnostic
parser (eg. tuple!) and generates the code to apply that parser to a byte-slice
input. There is also a bytes! macro to go the other way, applying a byte-slice
parser to a bit-stream input. Inside the bits! macro, you can use parsers that
consume individual bits. When switching from bit-stream to byte-slice parsing
(that is, at the end of the bits! macro or the beginning of a bytes! macro), if
there&amp;rsquo;s a partial byte remaining in the input it will be ignored and the
subsequent byte-slice parser will start parsing at the next whole byte. The only
two built-in bit-stream parsers are take_bits! (which consumes a given number
of bits from the input, and assembles them into the given integer type) and
tag_bits! which is like tag! but for bits.&lt;/p&gt;

&lt;p&gt;Unfortunately, at this point it isn&amp;rsquo;t possible to give names to each value in
a bits! macro like it is in do_parse!, so I had to make do with collecting the
mapper ID bits and the flag bits into a tuple instead.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/30d84186661c04a6d383278a18199e34.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;I went on to make some further changes, but they&amp;rsquo;re not related to nom so I&amp;rsquo;ll
skip the details. You can take a look at the &lt;a href=&#34;https://github.com/bheisler/Corrosion/blob/fdc4fa0334aabaa76518479dd0ad3e62e4e5ebb1/src/cart/ines.rs&#34;&gt;code&lt;/a&gt;
if you&amp;rsquo;re interested.&lt;/p&gt;

&lt;h2 id=&#34;impressions-of-nom&#34;&gt;Impressions of nom&lt;/h2&gt;

&lt;p&gt;I kind of like nom. There&amp;rsquo;s a rocky learning curve, and the documentation needs
some work. I&amp;rsquo;m also a bit wary of such heavy use of macros. Parsing is (often)
not performance-critical, so I&amp;rsquo;d be willing to sacrifice some runtime efficiency
to get some more help from the compiler when I make mistakes. On the other hand,
once you do get the hang of it, it&amp;rsquo;s quick and easy to define parsers for quite
complex data structures and the code reads a lot like a description of the format
to be parsed, which is always nice. nom has some beautifully clear example parsers
to look at (take &lt;a href=&#34;https://github.com/Geal/gif.rs&#34;&gt;this GIF parser&lt;/a&gt;,
for example). It works on both binary and text data as well, which is a plus.&lt;/p&gt;

&lt;p&gt;Overall, I would consider nom for future projects that involve parsing data. The
lack of documentation could cause some headaches, but it&amp;rsquo;s much easier and safer
to use a battle-tested library like nom than it is to write your own hand-written
parser for the same data.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;d like to check out the code or play around with some perfectly legal,
homebrew NES software, you can find it on
&lt;a href=&#34;https://github.com/bheisler/Corrosion&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calling Rust From Python</title>
      <link>https://bheisler.github.io/post/calling-rust-in-python/</link>
      <pubDate>Sun, 02 Apr 2017 00:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/calling-rust-in-python/</guid>
      <description>

&lt;p&gt;Hello! This is a detailed example of exposing Rust code to other languages (in
this case, Python). Most articles I&amp;rsquo;ve seen that cover this topic uses really
trivial example functions, skipping over a lot of the complexity. Even the better
ones out there typically don&amp;rsquo;t have a pre-existing, reasonably complex program
to work with. I&amp;rsquo;m going to start with trivial functions and build my way up to
being able to define a scene for my &lt;a href=&#34;https://github.com/bheisler/raytracer&#34;&gt;raytracer&lt;/a&gt;
in Python using a series of calls to Rust, then render it and return the
resulting image data back to Python. If you want to know more about the raytracer,
I wrote a series of posts on it &lt;a href=&#34;https://bheisler.github.io/post/writing-raytracer-in-rust-part-1/&#34;&gt;here&lt;/a&gt;,
but it won&amp;rsquo;t be necessary; I&amp;rsquo;ll explain parts of the raytracer here as we need
them. Hopefully this will give a more complete picture of how to incorporate
complex Rust code into Python.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve never written any sort of Python/C interop before, so this should be another
learning experience all around. I&amp;rsquo;m going to arbitrarily choose
&lt;a href=&#34;https://cffi.readthedocs.io/en/latest/&#34;&gt;CFFI&lt;/a&gt; as the Python interop library.
It&amp;rsquo;s portable across interpreters and seems nicer to use than &lt;a href=&#34;https://docs.python.org/2/library/ctypes.html&#34;&gt;ctypes&lt;/a&gt;.
I expect the main concepts will be broadly applicable to other libraries (and
other languages such as Ruby). Let get started!&lt;/p&gt;

&lt;h2 id=&#34;calling-functions&#34;&gt;Calling Functions&lt;/h2&gt;

&lt;p&gt;The first thing to do is to define a Rust function we want to call from Python.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/effc8c457c9d85d1e318be52e1b8c98d.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;We&amp;rsquo;re actually defining a function for Rust&amp;rsquo;s C foreign-function interface. The
basic idea here is that we write a wrapper in Python that knows how to call
C functions, and a wrapper in Rust that exposes C functions and translates them
to regular function calls in Rust. It&amp;rsquo;s sort of like we&amp;rsquo;re calling from Python
into C into Rust. The &lt;code&gt;no_mangle&lt;/code&gt; attribute and &lt;code&gt;extern &amp;quot;C&amp;quot;&lt;/code&gt; above instruct rustc
not to change the name of the function (otherwise CFFI wouldn&amp;rsquo;t be able to
find it later) and to emit a function that can be called as if it were written
in C. We&amp;rsquo;ll need both for all functions that we want to expose to C.&lt;/p&gt;

&lt;p&gt;Now we need to instruct Cargo to build this library as a dynamic library
(&amp;ldquo;dylib&amp;rdquo; in Cargo terms). I&amp;rsquo;m writing this on a Windows PC, so Cargo
produces a &lt;code&gt;raytracer_ffi.dll&lt;/code&gt; file. I tested it on Linux as well and it created
&lt;code&gt;libraytracer_ffi.so&lt;/code&gt;.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/06c25b67a35bfd8f5b38781256558230.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Then we need some Python code to load and call this shared library:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/ec798db12cd69153a6330e67eb6d3dac.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Let&amp;rsquo;s break this down a bit. First we import the &lt;code&gt;cffi&lt;/code&gt; module and create an
FFI object. Then we call &lt;code&gt;cdef&lt;/code&gt; and pass it some text - this text is a C function
signature matching the &lt;code&gt;double&lt;/code&gt; function in Rust. CFFI parses this function
signature in order to determine how to call the function. We&amp;rsquo;ll need to do this
for all of the functions and structs we want to expose to Python. Then we open
the DLL file with &lt;code&gt;dlopen&lt;/code&gt;. Finally, we call the &lt;code&gt;double&lt;/code&gt; function as if it were
a regular Python function and print the result.&lt;/p&gt;

&lt;p&gt;And now we should be able to call &lt;code&gt;double&lt;/code&gt; from Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python.exe test.py
18
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Side note: I wasn&amp;rsquo;t able to get this working with PyPy on 64-bit Windows. I
didn&amp;rsquo;t find out why, but I assume it has something to do with how PyPy only
provides 32-bit binaries. PyPy worked fine for me on Linux, but I had to use
64-bit CPython on Windows.&lt;/p&gt;

&lt;h2 id=&#34;passing-structures&#34;&gt;Passing Structures&lt;/h2&gt;

&lt;p&gt;Now, if I&amp;rsquo;m going to be able to define a scene in Python, I&amp;rsquo;ll need to be able
to call functions and pass in structs as arguments. I&amp;rsquo;ll keep working with this
toy program a bit longer, but instead of simply doubling an integer, let&amp;rsquo;s try
and get it to calculate the length of a vector using &lt;code&gt;vector::Vector3::length&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;First, I&amp;rsquo;ll need to tell rustc that Vector3 should be laid out like a C struct.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/23de3e8f86143ceea2240b2a283b8f91.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;It appears that CFFI doesn&amp;rsquo;t have any way to call functions with stack-allocated
structures. Using the stack for small, copyable structures like Vector3 is
pretty common in Rust, but I guess it isn&amp;rsquo;t in C? So instead, our Rust function
will have to accept a pointer to a Vector3.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/f02545b55a01f5602f9aa8802c970847.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Here we define an extern function which accepts a raw pointer to a Vector3.
Dereferencing raw pointers is unsafe, so we use an unsafe block to convert the
raw pointer to a Rust reference. Finally, we call &lt;code&gt;length()&lt;/code&gt; and return the value.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/d7c3c411f6826303a8a09868821b6829.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Back in Python-land, we define a structure type matching Vector3 and the
signature of the length function. Now we need to allocate a new vector_t object,
which is done with the &lt;code&gt;ffi.new()&lt;/code&gt; function. We need to pay attention to
ownership here - the memory for the vector_t is allocated by Python and it will
have to be freed by Python. In this case, it will be freed when the vector object
gets garbage collected so we don&amp;rsquo;t need to worry about it, but we&amp;rsquo;ll need to
be more careful about ownership later.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python.exe test.py
1.73205080757
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;returning-references-back-to-python&#34;&gt;Returning References Back To Python&lt;/h2&gt;

&lt;p&gt;Now we&amp;rsquo;ll start the process of building our actual FFI code. We&amp;rsquo;ll start with the
Scene structure. I don&amp;rsquo;t especially want to expose all the complexity of the
Scene structure to Python, so instead we&amp;rsquo;ll use another C idiom and return an
opaque pointer.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/9a552f490d320410b28ab5e6c065ee9f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Notice that we use &lt;code&gt;Box::new&lt;/code&gt; to heap-allocate the structure, and &lt;code&gt;Box::into_raw&lt;/code&gt;
to convert it into a raw pointer to return. The corresponding Python code is:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/fcdb3bc11c85147172e1a6ec42f224d0.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;I&amp;rsquo;m not actually sure &lt;code&gt;void*&lt;/code&gt; is the right way to go here, but I don&amp;rsquo;t know any
other way to do opaque pointers in this situation. If you know more about this,
let me know. CFFI seems to understand &lt;code&gt;uint32_t&lt;/code&gt; all on its own, and presumably
will call the Rust function with the appropriate integer width.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python.exe raytracer.py
From Rust: Scene { width: 800, height: 600, fov: 45, elements: [],
    lights: [], shadow_bias: 0.0000000000001, max_recursion_depth: 10 }
From Python: &amp;lt;cdata &#39;void*&#39; 0x000000000155B260&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sharp readers might have noticed that we&amp;rsquo;re leaking Scene objects - we&amp;rsquo;re
allocating some memory on the heap for the boxed Scene and never freeing it.
For this trivial example, it doesn&amp;rsquo;t matter much because it will be cleaned
up when the process terminates, but it is rather inelegant, so let&amp;rsquo;s fix that.&lt;/p&gt;

&lt;h2 id=&#34;disposing-of-allocated-objects&#34;&gt;Disposing Of Allocated Objects&lt;/h2&gt;

&lt;p&gt;This goes back to the brief discussion of ownership earlier. Previously,
Python owned the allocated Vector3 object, so we could trust that it would be
safely freed when it was garbage-collected. Now, we have an object allocated by
Rust, but owned by a pointer in Python. Python doesn&amp;rsquo;t know how to deallocate
an object owned by Rust, so we&amp;rsquo;ll have to return ownership of the pointer to
Rust and allow Rust to free the memory.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2f98fb5590e4dcd895773b1dd39a100d.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Freeing the memory is actually quite simple - we use &lt;code&gt;Box::from_raw&lt;/code&gt; to convert
the raw pointer back into a box, and then just let it fall out of scope. Rust
will automatically clean everything up for us.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/51656ea2be9b8d0c2e7ba2c6ba77bfe4.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Right now, there&amp;rsquo;s nothing to stop us from freeing the scene more than once,
or continuing to use that pointer after the scene has been freed. There&amp;rsquo;s nothing
we can do about that from the Rust side, but in Python we can at least build a
safe wrapper to work with.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/ba18f7b5c73c66ad9d1924e80881fc9e.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Here, we define a Python class to represent our Scene. It defines the &lt;code&gt;__enter__&lt;/code&gt;
and &lt;code&gt;__exit__&lt;/code&gt; methods necessary to act as a &lt;a href=&#34;https://www.python.org/dev/peps/pep-0343/&#34;&gt;Context Manager&lt;/a&gt;,
which allows us to use it with the &lt;code&gt;with&lt;/code&gt; statement at the end. Running this
file confirms that the scene object is being freed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python.exe raytracer.py
Freeing the scene
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;enums&#34;&gt;Enums&lt;/h2&gt;

&lt;p&gt;Before we begin constructing our scene in Python, however, there&amp;rsquo;s one more bit
of complexity to tackle first. Every object in this raytracer contains a Material
structure to define what color the surface is, whether it&amp;rsquo;s reflective or
transparent, etc. This is defined in Rust using some enums and a struct:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/5af67a2bc9fb63ad1c77e087d5857c91.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Rust&amp;rsquo;s enums have no equivalent in C, and even if they did that DynamicImage
type certainly doesn&amp;rsquo;t. We&amp;rsquo;ll have to create C-compatible wrappers for these
types that we can expose to Python. I&amp;rsquo;ll focus on the Coloration enum for now,
the SurfaceType enum will work the same way.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start by defining another enum:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/153001fea515624f8eaaf807640c79bb.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;I know, I just said we can&amp;rsquo;t do enums in C. Instead, we&amp;rsquo;ll define a couple of
functions to create CColoration values on the heap and return opaque pointers
to them like we did with the Scene.&lt;/p&gt;

&lt;p&gt;First, the simple case of a solid color:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/37004afc200aa009204031f1443a2ad9.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Then, the more complex case of a path to a texture file.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/8fc77676d46de395b661c89bb0f5384d.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Here we take a pointer to a null-terminated character array (a C-style string)
and convert it to a Rust string, which has a length and is encoded in UTF-8.
This conversion could fail, if the C string isn&amp;rsquo;t valid UTF-8. Notice that we
need to be very careful not to panic. We can&amp;rsquo;t just unwrap the result of
converting the CStr to a regular string, because panicking across FFI boundaries
is undefined behavior. Instead, we return a null pointer on all error
conditions. A more serious project would probably want to have more robust error
handling, but this is sufficient for now.&lt;/p&gt;

&lt;p&gt;The corresponding Python should be relatively familiar by now:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/02f53a18cc343e57b3a6e9b0c31678a4.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The SurfaceType enum works basically the same way as above, so I&amp;rsquo;ll spare you
the details.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/fbfb35e8b010c89e7b40cc5b93b65a2c.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;All those with&amp;rsquo;s are kind of ugly, but that&amp;rsquo;s the price we pay for safety.
We can verify that everything is being freed as expected:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ python.exe raytracer.py
Freeing surface type
Freeing surface type
Freeing surface type
Freeing coloration
Freeing coloration
Freeing coloration
Freeing coloration
Freeing coloration
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;constructing-the-scene&#34;&gt;Constructing the Scene&lt;/h2&gt;

&lt;p&gt;Finally, we&amp;rsquo;re ready to start constructing the scene. I&amp;rsquo;ll focus on the case of
adding a Sphere to the scene. The code to define other objects is pretty much
the same.&lt;/p&gt;

&lt;p&gt;First, we need a new struct to represent Material:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/b90e0a5de2bdbc16d0120142bf6b94ba.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;And a function to add a sphere to a scene:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/bede2aa436be20ede3c7c876f2f28488.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Most of this is the now-familiar C foreign-function boilerplate. The
&lt;code&gt;material.to_rust()&lt;/code&gt; method works pretty much as you&amp;rsquo;d expect - it
constructs a Material value from a CMaterial value, potentially loading the
texture contained in the &lt;code&gt;CColoration&lt;/code&gt;. More noteworthy is the way we convert
the scene Box back into a raw pointer at the end of the method. This prevents
Rust from deallocating our scene.&lt;/p&gt;

&lt;p&gt;You might reasonably ask why I chose to have one function that creates and adds
the sphere directly to the scene. This does, after all, make it impossible for
me to return a Sphere to Python. The answer is that since I don&amp;rsquo;t really want to
manipulate Spheres in Python, there&amp;rsquo;s not much point in going to all that extra
effort. You can go ahead and do that if you like.&lt;/p&gt;

&lt;p&gt;Now that we have all of that, we can call it from Python as before:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/690a6cc77c1e3ba295f5ce45798b6f26.js&#34;&gt;&lt;/script&gt;

&lt;pre&gt;&lt;code&gt;$ python.exe raytracer.py
Sphere { center: Point { x: 0, y: 0, z: -5 }, radius: 1, material:
  Material { coloration: Texture, albedo: 0.18, surface:
  Reflective { reflectivity: 0.7 } } }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;rendering-and-returning-the-image-to-python&#34;&gt;Rendering and Returning the Image To Python&lt;/h2&gt;

&lt;p&gt;Now that we can define a scene in Python, we need a way to render it and return
the resulting image. We can&amp;rsquo;t just return a byte array, because Python can&amp;rsquo;t
handle stack-allocated objects, and anyway it would overflow the stack. We could
return a pointer/length pair, but then we have to pass it back to Rust to free
it. Instead, we&amp;rsquo;ll follow the C convention and have the caller provide a buffer
to render the image into.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/5c3983559358ef40d4de64d83a44cf61.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;After the usual boilerplate, we convert the C-style byte array into a mutable
slice with the &lt;code&gt;slice::from_raw_parts_mut&lt;/code&gt; function, then wrap that into an
ImageBuffer and pass it to the raytracer for rendering. Slices in Rust don&amp;rsquo;t
own their contents, so we don&amp;rsquo;t need to do anything special to prevent Rust from
trying to free the buffer.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/51eb8b1f5ad6067942d8a1a969842185.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;In Python, we need to save the dimensions of the image so that we can allocate
an appropriate buffer. The raytracer uses 4-byte RGBA pixels, so we calculate
the buffer size as 4 * width * height, allocate an appropriate buffer, and
render the image into it. Then we call &lt;code&gt;ffi.buffer&lt;/code&gt; to wrap it into a convenient
Python object. Finally, we pass that to the Pillow library to be wrapped into
an Image object that we can save out to disk or do further processing on.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://imgur.com/a/knyif&#34;&gt;&lt;img src=&#34;https://bheisler.github.io/static/rendered-by-python.png&#34; alt=&#34;Rendered By Python&#34; /&gt;&lt;/a&gt;
Click to see high-resolution image&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Overall, this turned out to be easier than I&amp;rsquo;d expected. CFFI&amp;rsquo;s user-friendly
interface helped a lot, I think, though the Rust side has a lot of boilerplate.
I expect some macros or something could help with that. I&amp;rsquo;d like to thank Jake
Goulding and co. for the &lt;a href=&#34;http://jakegoulding.com/rust-ffi-omnibus/slice_arguments/&#34;&gt;Rust FFI Omnibus&lt;/a&gt;,
which covers all of the basic techniques listed above (and provides examples
for a number of other languages, if you&amp;rsquo;d like to compare).&lt;/p&gt;

&lt;p&gt;As usual, if you want to try playing around with the code yourself, you can
check out the &lt;a href=&#34;https://github.com/bheisler/raytracer&#34;&gt;GitHub Repository&lt;/a&gt;. If you
do, though, be careful with the complexity of the scene you try to render. It&amp;rsquo;s
very easy to reach multi-hour rendering times when you&amp;rsquo;re defining scenes
programmatically. Otherwise, enjoy!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Raytracer in Rust - Part 3 - Reflection and Refraction</title>
      <link>https://bheisler.github.io/post/writing-raytracer-in-rust-part-3/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/writing-raytracer-in-rust-part-3/</guid>
      <description>

&lt;p&gt;Hello again, and welcome to the final part of my series on writing a raytracer
in Rust (&lt;a href=&#34;https://bheisler.github.io/post/writing-raytracer-in-rust-part-1/&#34;&gt;Part 1&lt;/a&gt;,
&lt;a href=&#34;https://bheisler.github.io/post/writing-raytracer-in-rust-part-2/&#34;&gt;Part 2&lt;/a&gt;). Previously we implemented
a basic raytracer which could handle diffuse shading of planes and spheres with
multiple objects and multiple lights. This time, we&amp;rsquo;ll add texturing, reflection
and transparent objects.&lt;/p&gt;

&lt;p&gt;First, I&amp;rsquo;ve refactored the common parts of Sphere and Plane out to a separate
structure. Since this post is all about handling more complex surface properties,
we&amp;rsquo;ll need a structure to represent them and avoid duplication.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/f49634600ec7910c149e577804a5e3cc.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;texturing&#34;&gt;Texturing&lt;/h2&gt;

&lt;p&gt;In order to texture our objects, we need to do two things. First, we need to
calculate the texture coordinates corresponding to the point on the object that
the ray intersected. Then we need to look up the color at those coordinates.
We&amp;rsquo;ll start by introducing a structure to contain our texture coordinates and a
function to calculate them.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/952f43be37463e22d7db93800f12ee21.js&#34;&gt;&lt;/script&gt;

&lt;h3 id=&#34;spheres&#34;&gt;Spheres&lt;/h3&gt;

&lt;p&gt;The texture coordinates of a sphere are simply the spherical coordinates of the
intersection point. If our sphere were the Earth, these would be akin to the
latitude and longitude.&lt;/p&gt;

&lt;p&gt;We can compute the (x, y, z) coordinates of the intersection relative to the
center of the sphere by using the vector subtraction of the hit point and the
center of the sphere. Then, we can convert those to the spherical coordinates
using these formulas:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;phi = atan(z, x)
theta = acos(y/R) //Where R is the radius of the sphere
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If your trigonometry is rusty, check out &lt;a href=&#34;https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/geometry/spherical-coordinates-and-trigonometric-functions&#34;&gt;this explanation&lt;/a&gt;
at (you guessed it)
Scratchapixel. If you do though, be aware that their coordinates have the Z and
Y axes swapped so they have slightly different formulas.&lt;/p&gt;

&lt;p&gt;These formulas produce values in the range (-pi&amp;hellip;pi) and (0&amp;hellip;pi) respectively.
We want (0&amp;hellip;1) instead so we&amp;rsquo;ll adjust the formula to remap the values to the
correct range:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tex.x = (1 + atan(z, x) / pi) * 0.5
tex.y = acos(y) / pi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have something we can implement in code, like so:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/fe8a5ba0f4ee0f7d835b100126220636.js&#34;&gt;&lt;/script&gt;

&lt;h3 id=&#34;planes&#34;&gt;Planes&lt;/h3&gt;

&lt;p&gt;To calculate the texture coordinates on a plane, we first need to construct a
coordinate system (that is, two perpendicular unit vectors) aligned with that
plane. This can be done using the cross product, which takes two vectors and
produces a new vector which is perpendicular to them. In this case, we use the
surface normal and the forward vector (unless the normal is equal to the forward
vector, in which case use the up vector). This produces one vector parallel to
the plane to be our X axis. To get the other vector, we can just cross the
normal with the X axis.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/0c2213af556812edd3bae4f9827a666c.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Then we can compute the texture coordinates by taking the dot product of the
vector from the hit location to the origin against the axes (effectively
separating the hit vector into its X and Y components).&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/c6f60e809599459aa216bfb0391b3adf.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;It might be useful to add a scaling factor and an offset to allow the user to
adjust the position and size of the texture, but this is left as an exercise for
the reader.&lt;/p&gt;

&lt;p&gt;Next we need to add the texture to our scene.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/655602ee3ed04f35a98a2e4d7a5240a4.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Then we can look up the color based on the texture coordinates.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/f7aa43da0d4a535085b3af2b01538224.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/textured-objects.png&#34; alt=&#34;Textured Objects&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;reflection&#34;&gt;Reflection&lt;/h2&gt;

&lt;p&gt;Conceptually, implementing reflection in a raytracer is quite simple. When a ray
hits a reflective object, just trace another ray out from the intersection at
the appropriate angle - recursively if necessary - and mix the color value from
that ray in with the color value of the first ray.&lt;/p&gt;

&lt;p&gt;As usual, the first thing to do is extend the scene definition. Since the
reflection process is recursive, we also add a value for the maximum recursion
depth. Deeper recursion will produce a more accurate image, but at the cost of
increased rendering time.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/0ff69bf512f8f62ce59d09ec79f222ad.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The reflectivity controls how much of the final pixel color comes from the
reflection and how much from the object itself. If the reflectivity is zero,
we&amp;rsquo;ll use the diffuse color and there will be no reflection. If the reflectivity
is one, we&amp;rsquo;ll use the reflected color and the object will appear to be a
perfect mirror. If the value is somewhere in between, we could get effects
ranging from &amp;lsquo;glossy surface&amp;rsquo; to &amp;lsquo;tinted chrome.&amp;rsquo;&lt;/p&gt;

&lt;p&gt;Since the last part, I&amp;rsquo;ve extracted most of what was in get_color into a function
for doing diffuse shading so that we can use get_color for mixing together the
reflection and diffuse colors.&lt;/p&gt;

&lt;p&gt;As you can see, we construct a reflection ray and trace it through the scene
like with our prime ray, then mix it in with the diffuse color. We also track
the current recursion depth and simply return black if we reach the limit.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/ed31642dcd5a3b58ea1912348e5ae70c.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The more interesting question here is how to compute the reflection ray. If
you&amp;rsquo;ve taken physics, you may remember the mantra that the angle of incidence
equals the angle of reflection. That&amp;rsquo;s helpful enough as far as it goes, but
how do we actually calculate that in terms of vectors?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/reflection-ray.png&#34; alt=&#34;Reflection Ray&#34; align=&#34;right&#34;&gt;&lt;/p&gt;

&lt;p&gt;We can separate the incident vector I into two vectors, A and B (see figure)
such that I = A + B. The reflection vector R is then equal to A - B.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;I = A + B
R = A - B
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can compute B quite easily - it&amp;rsquo;s the projection of I onto the surface normal,
or the dot product of I and N multiplied by N.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;B = (I.N)N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Substitute that into both equations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;I = A + (I.N)N
R = A - (I.N)N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then solve the first equation for A:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A = I - (I.N)N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And substitute into the second equation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;R = I - (I.N)N - (I.N)N
R = I - 2(I.N)N
&lt;/code&gt;&lt;/pre&gt;

&lt;script src=&#34;//gist.github.com/bheisler/3a29db0b3104d4420e80523268f3607a.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;We also adjust the origin slightly along the surface normal to avoid the same
floating-point precision problems we had with our shadows earlier.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://imgur.com/a/Kuwks&#34;&gt;&lt;img src=&#34;https://bheisler.github.io/static/reflective-objects.png&#34; alt=&#34;Reflective Objects&#34; /&gt;&lt;/a&gt;
Click to see high-resolution image. Note the recursive reflections between the
center sphere and the floor.&lt;/p&gt;

&lt;h2 id=&#34;refraction&#34;&gt;Refraction&lt;/h2&gt;

&lt;p&gt;Refraction is again conceptually simple in a raytracer - trace a secondary ray
(called the transmission ray) through the object in the appropriate direction
and mix it in with the color of the object. Unfortunately, the math to construct
the transmission ray is a lot more complex than it is to construct the
reflection ray. But first, some definitions:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/04fc2c624e4c3cfae1171a2660a16c2a.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The transparency is the same as the reflectivity from before - the fraction of
the final color that comes from refraction. Refraction is governed by a parameter
called the index of refraction. When a ray of light passes from one transparent
substance to another, it bends at an angle described by Snell&amp;rsquo;s Law:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/Snells_law2.svg&#34; alt=&#34;Snell&#39;s Law&#34; align=&#34;right&#34;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sin(theta_i)/sin(theta_t) = eta_t/eta_i
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where theta_i and theta_t are the angle of incidence and angle of transmission,
and eta_i and eta_t are the indices of refraction for the incident substance and
the transmitting substance. We could calculate the angle of transmission using
this equation, but we&amp;rsquo;ll need to do more to convert that angle into a vector.&lt;/p&gt;

&lt;p&gt;As with reflection, refraction is really a two-dimensional process in the plane
formed by the incident vector and the surface normal. This means that we can
think of our transmitted ray as having a horizontal component (A) and vertical
component (B). B is relatively simple to calculate:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;B = cos(theta_t) * -N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This makes some intuitive sense - the transmitted ray will be on the opposite
side of the surface from the incident ray, so it&amp;rsquo;s vertical component will be
some fraction of the inverse of the surface normal. We use the cosine of the
transmission angle because that&amp;rsquo;s how you calculate the vertical distance.&lt;/p&gt;

&lt;p&gt;We can use this same approach to get the horizontal component A, but first we
need to construct a horizontal unit vector (M). To do this, we first take the
incident vector and subtract it&amp;rsquo;s vertical component, leaving only the
horizontal component. We can calculate the vertical component of I easily -
it&amp;rsquo;s (I.N)N, just like before. Then we normalize this horizontal vector to get
the horizontal unit vector we need. We can slightly cheat here, though - the
length of the horizontal component of I will be equal to sin(theta_i), so we
can normalize using that instead of computing the vector length the slow way.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;M = (I - -N(I.N)) / sin(theta_i) = (I + N(I.N)) / sin(theta_i)
A = sin(theta_t) * M
B = cos(theta_t) * -N
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Putting this all back together, we get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T = A + B
T = (sin(theta_t) * M) - N * cos(theta_t)
T = (sin(theta_t) * (I + N(I.N)) / sin(theta_i)) - N * cos(theta_t)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can use Snell&amp;rsquo;s Law to replace that sin(theta_t) / sin(theta_i) with
eta_i/eta_t, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T = (I + N(I.N)) * eta_i/eta_t - N * cos(theta_t)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We could calculate cos(theta_t) from Snell&amp;rsquo;s Law and theta_i, but this involves
lots of trigonometry, and ain&amp;rsquo;t nobody got time for that. Instead, we can
express that in terms of a dot-product. We know from trigonometry that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cos^2(theta_t) + sin^2(theta_t) = 1
cos(theta_t) = sqrt(1 - sin^2(theta_t))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And from Snell&amp;rsquo;s Law we know that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sin(theta_t) = (eta_i/eta_t) * sin(theta_i)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Therefore:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cos(theta_t) = sqrt( 1 - (eta_i/eta_t)^2 * sin^2(theta_1) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can use the same trigonometric identity from above to convert that sin
to a cosine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cos(theta_t) = sqrt( 1 - (eta_i/eta_t)^2 * (1 - cos^2(theta_i)) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And since cos(theta_i) = I.N, we get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cos(theta_t) = sqrt( 1 - (eta_i/eta_t)^2 * (1 - I.N^2) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And so, finally, we arrive at this monster of an equation (but look, no trigonometry):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T = (I + N(I.N)) * eta_i/eta_t - N * sqrt( 1 - (eta_i/eta_t)^2 * (1 - I.N^2) )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, there are a couple of wrinkles left to sort out. First, sometimes our ray
will be leaving the transparent object rather than entering it. This is easy
enough to handle, just invert the normal and swap the indices of refraction. We
also need to handle total internal reflection. In some cases, if the angle of
incidence is shallow enough, the refracted light ray actually reflects off the
surface instead of passing through and travels back into the object. We can
detect this when the term inside the sqrt is negative. Again, this makes
intuitive sense - if that&amp;rsquo;s negative, the vertical component of the transmission
vector would be positive (remember, B is a multiple of -N) and therefore on the
same side of the surface as the incident vector. In fact, however, we can handle
this by completely ignoring it, and I&amp;rsquo;ll explain why later.&lt;/p&gt;

&lt;p&gt;Whew! Now that we have that giant equation, we can implement it in code, like so:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/ceba1d949b9b766a03d275534f016fd3.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;I also discovered a nasty bug in my sphere-intersection code while testing this.
If you&amp;rsquo;re following along at home, this could be a good opportunity to practice
your debugging. Go ahead, I&amp;rsquo;ll wait.&lt;/p&gt;

&lt;p&gt;Hint: What happens if the ray origin is inside the sphere?&lt;/p&gt;

&lt;p&gt;Find it? It turns out that the sphere-intersection test will return a point
behind the origin of the ray if the origin is inside the sphere. The refraction
ray will then intersect the sphere again, creating another refraction ray and
so on until we hit the recursion limit. This took hours of painful debugging to
find because I was looking for bugs in the create_transmission function. I
didn&amp;rsquo;t realize that it was something else until I tried to create a refractive
plane and noticed that it appeared to behave correctly.&lt;/p&gt;

&lt;p&gt;Anyway, here&amp;rsquo;s the corrected sphere-intersection function:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/393169985793f91cdd71b5616faace99.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&#34;http://imgur.com/a/T9F6O&#34;&gt;&lt;img src=&#34;https://bheisler.github.io/static/initial-refraction.png&#34; alt=&#34;Initial Refraction&#34; /&gt;&lt;/a&gt;
Click to see high-resolution image. Notice the refracted image of the floor in
the transparent sphere.&lt;/p&gt;

&lt;h2 id=&#34;fresnel&#34;&gt;Fresnel&lt;/h2&gt;

&lt;p&gt;However, we&amp;rsquo;re not quite done yet. If you&amp;rsquo;ve ever noticed how glass buildings or
smooth lakes look like mirrors far away but clear up close, you know that
transparent surfaces reflect light as well as transmitting it. It&amp;rsquo;s often even
possible to see this effect in the polished floors of long hallways. These
reflections are governed by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fresnel_equations&#34;&gt;Fresnel Equations&lt;/a&gt;
and we&amp;rsquo;ll have to simulate them to render refractive objects more accurately.
Incidentally, this is why we can ignore total internal reflection
in our transmission code above - the Fresnel code will cover that for us.
We already know how to handle reflection in our code, but we need to calculate
how much of a ray&amp;rsquo;s color comes from the refraction and how much from the
reflection.&lt;/p&gt;

&lt;p&gt;The derivation of the Fresnel Equations is hairy enough that Scratchapixel
doesn&amp;rsquo;t even try to explain it. Serious physics-lovers might want to check out
&lt;a href=&#34;http://physics.gmu.edu/~ellswort/p263/feqn.pdf&#34;&gt;this derivation&lt;/a&gt; (PDF), but
this is getting out of my depth so I&amp;rsquo;ll just take the final equations as given.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/fresnel-equations.png&#34; alt=&#34;Fresnel Equations&#34; align=&#34;center&#34;&gt;&lt;/p&gt;

&lt;p&gt;Fortunately for me, Scratchapixel does include some C++ code implementing these
equations that I can simply translate to Rust:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/767895b07240a346bcf4353826d269f3.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;And now that we have that, we can put it all together:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2d072e000863e30c7337d3588ff81291.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&#34;http://imgur.com/EvmGhQW&#34;&gt;&lt;img src=&#34;https://bheisler.github.io/static/complete-refraction.png&#34; alt=&#34;Complete Refraction&#34; /&gt;&lt;/a&gt;
Click to see high-resolution image&lt;/p&gt;

&lt;p&gt;Beautiful, isn&amp;rsquo;t it?&lt;/p&gt;

&lt;h2 id=&#34;addendum-gamma-correction&#34;&gt;Addendum - Gamma Correction&lt;/h2&gt;

&lt;p&gt;After I posted this article, &lt;a href=&#34;https://github.com/fstirlitz&#34;&gt;fstirlitz&lt;/a&gt;
&lt;a href=&#34;https://github.com/bheisler/raytracer/issues/2&#34;&gt;pointed out&lt;/a&gt; that the lighting
was a bit off because my code wasn&amp;rsquo;t handling Gamma Correction correctly (or at
all). I had noticed the strange lighting effects but had simply assumed they
were an artifact of my relatively simple rendering process, and that a more
advanced renderer would solve them.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll spare you a detailed discussion of what Gamma Correction is (if you&amp;rsquo;re
interested, see &lt;a href=&#34;http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/&#34;&gt;What Every Coder Should Know About Gamma&lt;/a&gt; by John Novak).
The short version is that human perception of light is non-linear. Our screens
account for that by applying a power-law formula to the pixel values before
displaying them. Correspondingly, image formats expect the pixel values to be
in this non-linear color space, where my raytracer was writing out pixels in a
linear color space. Likewise, when reading textures, it was reading non-linear
color values and treating them as if they were linear. This mismatch caused
the image to be generally darker, with sharper divisions between light and dark
shades than the human eye would have seen.&lt;/p&gt;

&lt;p&gt;Fortunately, this is pretty easy to fix:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/972da2540646d4195b23a76db9fdd3ac.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;I&amp;rsquo;ve only implemented the basic power-law formula rather than the more complex
sRGB conversion, but it&amp;rsquo;s good enough for now.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://imgur.com/a/tNhlk&#34;&gt;&lt;img src=&#34;https://bheisler.github.io/static/gamma-corrected.png&#34; alt=&#34;Gamma Corrected&#34; /&gt;&lt;/a&gt;
Click to see high-resolution image&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is the end of my series on raytracing, at least for now. There are many,
many things I didn&amp;rsquo;t even begin to cover here. For instance, you might notice
how the two lights in this scene don&amp;rsquo;t glint off the reflective objects the
way real lights would, and how the glass sphere on the right doesn&amp;rsquo;t focus
light rays on the floor like real glass would. If you&amp;rsquo;re interested, I encourage
you to dig deeper - I may return to this subject myself in the future. Until
then, I hope you&amp;rsquo;ve enjoyed reading.&lt;/p&gt;

&lt;p&gt;As before, if you want to try playing around with the code yourself, you can
check out the &lt;a href=&#34;https://github.com/bheisler/raytracer&#34;&gt;GitHub Repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Raytracer in Rust - Part 2 - Light and Shadow</title>
      <link>https://bheisler.github.io/post/writing-raytracer-in-rust-part-2/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/writing-raytracer-in-rust-part-2/</guid>
      <description>

&lt;p&gt;Welcome to Part 2 of my series on writing a raytracer in Rust. If you haven&amp;rsquo;t
already, you may wish to read &lt;a href=&#34;https://bheisler.github.io/post/writing-raytracer-in-rust-part-1/&#34;&gt;Part 1&lt;/a&gt;.
Previously, we implemented a basic raytracer which can render only a single
sphere with no lighting. This time, we&amp;rsquo;ll add multiple objects, planes, and
basic lighting.&lt;/p&gt;

&lt;h2 id=&#34;multiple-objects&#34;&gt;Multiple Objects&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s pretty easy to change our scene definition to contain a Vec of spheres
instead of just a single one. Once we have multiple spheres, however, we need to
know which one our ray hit. This is easy if they don&amp;rsquo;t overlap on the screen.
If they do, we can find the correct sphere by taking the nearest intersection
to our camera. That means we need to know the distance to the intersection, not
just whether there is an intersection or not.&lt;/p&gt;

&lt;p&gt;This requires a bit more geometry. Recall from last time that we detect an
intersection by constructing a right triangle between the camera origin and the
center of the sphere. We can calculate the distance between the center of the
sphere and the camera, and the distance between the camera and the right angle
of our triangle. From there, we can use Pythagoras&amp;rsquo; Theorem to calculate the
length of the opposite side of the triangle. If the length is greater than the
radius of the sphere, there is no intersection.&lt;/p&gt;

&lt;p&gt;There are more right triangles formed by the ray than just this one, however.
If we instead create a triangle between the point that the ray intersects the
sphere and the center of the sphere, we can again use Pythagoras&amp;rsquo; Theorem to
calculate the distance from our right angle to the intersection point.
Subtracting that from the distance from the camera to the right angle gives the
distance to the intersection point.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/intersection-distance.png&#34; alt=&#34;Intersection Distance&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To put that in code, here are the changes to our Sphere intersection method:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/27f0fc17de209662a04cd6393a8731c3.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Now that we know the distance to the intersection, we need a method to perform
the iteration and return the nearest intersection. It&amp;rsquo;s also useful to return
a reference to the object itself (for example, so we can use the right color).
Notice that we have to use partial_cmp and unwrap to compare the distances. This
is an instance where Rust&amp;rsquo;s strict type safety sort of gets in the way - because
some values (NaN, +-Infinity) can&amp;rsquo;t be correctly compared, f64 doesn&amp;rsquo;t implement
the Cmp trait. In this case, no valid intersection can ever contain those values
so we should be safe just using unwrap. It&amp;rsquo;s a bit ugly, but
it&amp;rsquo;s probably better than tracking down strange bugs related to NaN-safety later.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/95ffb04905984a10fe00580851e19380.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;planes&#34;&gt;Planes&lt;/h2&gt;

&lt;p&gt;Next up we&amp;rsquo;ll add Planes as an object to test our rays against. There are a few
ways to represent planes in 3D space, but for our purposes the most convenient
is to define a point on the plane, and the normal of the surface. Before we
implement the intersection test though, we need to adapt our scene structure
so it can contain an arbitrary number of spheres or planes.&lt;/p&gt;

&lt;p&gt;We could try adding another Vec of Plane structures, but that gets annoying
quickly. We&amp;rsquo;d have to duplicate some logic (eg. the trace method) to apply to
both the spheres and the planes. Some sort of dynamic dispatch is appropriate
here. Rust provides two ways to do this. We could either wrap each object in a
variant of an Enum or we could use
&lt;a href=&#34;https://doc.rust-lang.org/book/trait-objects.html&#34;&gt;Trait Objects&lt;/a&gt;. I&amp;rsquo;ve chosen
to go with the former, but it&amp;rsquo;s mostly a matter of personal preference.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/7c4f1d7580a79c636d8b1ddfaecd652f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Now that we have our Plane structure, how can we test for an intersection?
One convenient property of planes is that they&amp;rsquo;re infinitely large. If a plane
isn&amp;rsquo;t perfectly parallel to our ray, it will always intersect eventually.
We can test this with the dot product - if the dot product between the ray and
the normal of the plane is zero (give or take a bit to account for
floating-point error) then it&amp;rsquo;s parallel and thus there is no intersection.
Otherwise, there is an intersection somewhere.&lt;/p&gt;

&lt;p&gt;However, we need to know where that intersection is. I&amp;rsquo;m afraid that I haven&amp;rsquo;t
been able to find a good intuitive or geometric explanation of why this works,
so I&amp;rsquo;ll just have to direct you to
&lt;a href=&#34;https://www.scratchapixel.com/lessons/3d-basic-rendering/minimal-ray-tracer-rendering-simple-shapes/ray-plane-and-ray-disk-intersection&#34;&gt;Scratchapixel&lt;/a&gt;,
where they show the full derivation of the equation.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/388e88f4cb2ecb391c63aabd76859c5f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Now that all of that&amp;rsquo;s done, let&amp;rsquo;s take a moment to admire our handywork.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/spheres-and-planes.png&#34; alt=&#34;Spheres and Planes&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yeah, I know. Five minutes in MS Paint, amirite? It will look better once we
start adding lighting effects.&lt;/p&gt;

&lt;h2 id=&#34;directional-lights&#34;&gt;Directional Lights&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll start by adding a single directional light to our scene. Directional lights
approximate light from the sun or stars - objects so far away that their light
rays are effectively parallel to each other and at an approximately-constant
intensity level. As a result, they&amp;rsquo;re also simpler than closer point-source
lights.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/5884657ad43bb968c8dbcedddfe72faf.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Next we need to know the surface normal of the object at the point our ray
intersected with it.&lt;/p&gt;

&lt;p&gt;Sphere:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fn surface_normal(&amp;amp;self, hit_point: &amp;amp;Point) -&amp;gt; Vector3 {
    (*hit_point - self.center).normalize()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Plane:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fn surface_normal(&amp;amp;self, _: &amp;amp;Point) -&amp;gt; Vector3 {
    -self.normal
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we&amp;rsquo;ll need to add an albedo to our Spheres and Planes. This is simply
a parameter which specifies how much light energy is reflected by an object and
how much is absorbed.&lt;/p&gt;

&lt;p&gt;Now to actually implement the shading. First some preparation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let intersection = scene.trace(&amp;amp;ray);
let hit_point = ray.origin + (ray.direction * intersection.distance)
let surface_normal = intersection.element.surface_normal(&amp;amp;hit_point)
let direction_to_light = -scene.light.direction
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we calculate the amount of light that lands on this point. This is
proportional to the cosine of the angle between the surface normal and the
direction to the light (&lt;a href=&#34;https://en.wikipedia.org/wiki/Lambert%27s_cosine_law&#34;&gt;Lambert&amp;rsquo;s Cosine Law&lt;/a&gt;).
The dot product is the length of one vector times the
cosine of the angle between them, but because we use normalized vectors the
length will be one. We also add a factor for the brightness of the light.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let light_power = (surface_normal.dot(&amp;amp;direction_to_light) as f32) *
    scene.light.intensity;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we calculate the proportion of the light which is reflected. This is equal
to the albedo of the object divided by Pi. Once again I have to admit that I
can&amp;rsquo;t find a good explanation of this formula. If you&amp;rsquo;re really interested, you
can once again check out Scratchapixel&amp;rsquo;s
&lt;a href=&#34;https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/diffuse-lambertian-shading&#34;&gt;derivation&lt;/a&gt;
(be warned - this one contains integrals). The short version is that dividing by
Pi ensures that the object doesn&amp;rsquo;t reflect away more energy than it receives.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let light_reflected = intersection.element.albedo() / std::f32::consts::PI;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally we accumulate this together into the final color for the pixel.
We represent colors as (R, G, B) triplets where each value is in the range
0.0&amp;hellip;1.0. We can multiply colors by multiplying each value - eg. if the red
component of a light is 0.5 and the object reflects 0.5 of red light, the viewer
will receive a red value of 0.25.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let color = intersection.element.color() * scene.light.color *
            light_power * light_reflected;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, all together:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/7fe4960b607344aa57a06d4712685ab5.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/directional-lighting.png&#34; alt=&#34;Directional Lighting&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s still not quite right though - none of the spheres are casting shadows, on
the lower plane or on each other.&lt;/p&gt;

&lt;h2 id=&#34;shadows&#34;&gt;Shadows&lt;/h2&gt;

&lt;p&gt;Calculating shadows in a raytracer is really easy. Simply trace another ray from
the intersection of the prime ray and the object back to the light. If there is
another object between the intersection and the light, the point is in shadow.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/14fae787f7092ad068a572d9b406d10f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/shadow-acne.png&#34; alt=&#34;Shadow Acne&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Well, that&amp;rsquo;s not quite right. We have shadows on the lower plane and the green
sphere, but also a lot of noise. The dark noise is called &amp;lsquo;shadow acne&amp;rsquo; and
it occurs because our floating point values have limited precision. Sometimes,
the hit point will be ever so slightly inside the intersected object and so the
shadow ray will intersect with the same object the prime ray did. It might seem
like we could simply ignore that object when tracing the shadow ray, and for
this simple geometry we could. If we had more complex objects though (eg. a model of
a tree) we would want an object to be able to cast shadows on itself, so that
won&amp;rsquo;t work. Instead, we simply add a tiny fudge factor and adjust the origin
of the shadow ray a short distance along the surface normal so that we can be
sure it&amp;rsquo;s outside the object. It doesn&amp;rsquo;t have to be much - I&amp;rsquo;ve found that bias
values as small as 1e-13 were enough to eliminate visible shadow acne.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let shadow_ray = Ray {
    origin: hit_point + (surface_normal * scene.shadow_bias),
    direction: direction_to_light,
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/shadows.png&#34; alt=&#34;Shadows&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;multiple-lights&#34;&gt;Multiple Lights&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s pretty easy to implement multiple lights as well. The light the camera sees
from any particular point is equal to the sum of the contributions from each
individual light source. We can just iterate through the lights, accumulating
together the color values from each.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/c6186ef183ed98fccd02c119c2cc01a4.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;This produces the following image - notice the two sets of shadows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/multiple-lights.png&#34; alt=&#34;Multiple Lights&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;spherical-lights&#34;&gt;Spherical Lights&lt;/h2&gt;

&lt;p&gt;Finally, we&amp;rsquo;ll add Spherical Lights (or point lights). First some definitions.
Again, I&amp;rsquo;m using an enum for dynamic dispatch.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2aad485bfef7087438c493e3ca6a5bdc.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Next up, we need to know the direction to the light. This is easily calculated:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(s.position - *hit_point).normalize()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The intensity of these lights obeys the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Inverse-square_law&#34;&gt;Inverse Square Law&lt;/a&gt;, so we
calculate the intensity by dividing the light&amp;rsquo;s intensity value by 4*Pi*distance^2.
Incidentally, this means that the intensity values of spherical lights in your
scene definition must be much larger than for directional lights.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let r2 = (s.position - *hit_point).norm() as f32;
s.intensity / (4.0 * ::std::f32::consts::PI * r2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Additionally, our shadow test needs to be changed a bit. For directional lights,
we only had to check if there was any intersection in the direction of the light.
That won&amp;rsquo;t work now - what if there&amp;rsquo;s an object on the far side of the light?
Instead we check if the nearest intersection is closer than the light itself is.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let shadow_intersection = scene.trace(&amp;amp;shadow_ray);
let in_light = shadow_intersection.is_none() ||
    shadow_intersection.unwrap().distance &amp;gt; light.distance(&amp;amp;hit_point);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Putting that all together produces this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/spherical-lights.png&#34; alt=&#34;Spherical Lights&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Try doing that in five minutes in MS Paint!&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve taken this toy raytracer from producing an image of a green circle to a
nicely-lit scene containing multiple objects. The &lt;a href=&#34;https://bheisler.github.io/post/writing-raytracer-in-rust-part-3/&#34;&gt;last entry&lt;/a&gt;
in this series will go on to add texturing as well as simple reflection and
refraction simulations. As before, if you want to try playing around with the
code yourself, you can check out the
&lt;a href=&#34;https://github.com/bheisler/raytracer&#34;&gt;GitHub Repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a Raytracer in Rust - Part 1 - First Rays</title>
      <link>https://bheisler.github.io/post/writing-raytracer-in-rust-part-1/</link>
      <pubDate>Mon, 20 Feb 2017 11:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/writing-raytracer-in-rust-part-1/</guid>
      <description>

&lt;p&gt;Hello! This is part one of a short series of posts on writing a simple raytracer
in Rust. I&amp;rsquo;ve never written one of these before, so it should be a learning
experience all around.&lt;/p&gt;

&lt;p&gt;So what is a raytracer anyway? The short version is it&amp;rsquo;s a computer program that
traces the paths of simulated rays of light through a scene to produce
high-quality 3D-rendered images. Despite that, it also happens to be the simplest
way to render 3D images. Unfortunately, that comes at a cost in render time -
raytracing an image takes much longer than the polygon-based rendering done by
most game engines. This means that raytracing is typically used to produce
&lt;a href=&#34;http://hof.povray.org/&#34;&gt;beautiful still images&lt;/a&gt; or pre-rendered video (eg.
Pixar&amp;rsquo;s &lt;a href=&#34;https://renderman.pixar.com/&#34;&gt;RenderMan&lt;/a&gt; technology).&lt;/p&gt;

&lt;p&gt;For the purposes of this post, I&amp;rsquo;ll assume that you&amp;rsquo;re familiar with what
vectors are and how they work, as well as basic geometry. If you aren&amp;rsquo;t, check
out the first three pages of Scratchapixel&amp;rsquo;s
&lt;a href=&#34;https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/geometry/points-vectors-and-normals&#34;&gt;excellent series&lt;/a&gt;
on geometry and linear algebra. You don&amp;rsquo;t need to know Rust specifically (though
I recommend it, it&amp;rsquo;s a great language) but you should at least be familiar with
C-family programming languages. If you want to build the code however, you will
need to install &lt;a href=&#34;https://rustup.rs/&#34;&gt;Cargo&lt;/a&gt;, which is the standard Rust build
tool.&lt;/p&gt;

&lt;h2 id=&#34;defining-the-scene&#34;&gt;Defining the Scene&lt;/h2&gt;

&lt;p&gt;The first thing to do is decide exactly what our scene (and therefore our
renderer) will be able to handle. For this first post, it won&amp;rsquo;t be much. One
lonely sphere, hanging in the darkness. No lighting, reflection, or transparency.
No other shapes. We&amp;rsquo;ll extend this basic scene over the rest of this series.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start by defining some structures to hold our scene data:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/bf4247cf7921d8c449e3cd62f323519d.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;And a stub render method and simple test case. I&amp;rsquo;m using the
&lt;a href=&#34;https://crates.io/crates/image&#34;&gt;image crate&lt;/a&gt; to set up the image buffer and
write the resulting render to a PNG file. This is all pretty straightforward
except for the position of the sphere - (0.0, 0.0, -5.0). I&amp;rsquo;ll explain that
later.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/1eb2e5fadc9edb680760360ee53f9a78.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;prime-ray-generation&#34;&gt;Prime Ray Generation&lt;/h2&gt;

&lt;p&gt;The basic idea of how a raytracer like this works is that we iterate over every
pixel in the finished image, then trace a ray from the camera out through that
pixel to see what it hits. This is the exact opposite of how real light works,
but it amounts to pretty much the same thing in the end. Rays traced from the
camera are known as prime rays or camera rays. There is actually a lot of
freedom in how we translate pixel coordinates to prime rays, which confused me
for a while, but it&amp;rsquo;s pretty simple if you follow common conventions.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll start with defining a Ray structure and a static function for generating
prime rays:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/e8f47c4cad5b1210231d66200846f653.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;By convention, the camera is aligned along the negative z-axis, with positive x
towards the right and positive y being up. That&amp;rsquo;s why the sphere is at
(0.0, 0.0, -5.0) - it&amp;rsquo;s directly centered, five units away from the camera.
We&amp;rsquo;ll start by pretending there&amp;rsquo;s a two-unit by two-unit square one unit in
front of the camera. This square represents the image sensor or film of our camera.
Then we&amp;rsquo;ll divide that sensor square into pixels, and use the directions to each
pixel as our rays. We need to translate the (0&amp;hellip;800, 0&amp;hellip;600) coordinates of our
pixels to the (-1.0&amp;hellip;1.0, -1.0&amp;hellip;1.0) coordinates of the sensor. I&amp;rsquo;ll start
with the finished code for this step, then explain it in more detail.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/be79c6e0871e4308443c0d4e61318fed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Let&amp;rsquo;s unpack that a bit and focus on only the x component. The y component is
almost exactly the same.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let pixel_center = x as f64 + 0.5;
let normalized_to_width = pixel_center / screen.width as f64;
let adjusted_screen_pos = (normalized_to_width * 2.0) - 1.0;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First, we cast to float and add 0.5 (one half-pixel) because we want our ray to
pass through the center (rather than the corner) of the pixel on our imaginary
sensor. Then we divide by the image width to convert from our original
coordinates (0&amp;hellip;800) to (0.0&amp;hellip;1.0). That&amp;rsquo;s almost, but not quite, the
(-1.0&amp;hellip;1.0) coordinates we want, so we multiply by two and subtract one. That&amp;rsquo;s
all there is to it! The y calculation follows the same basic process except the
last step:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;let adjusted_screen_pos = 1.0 - (normalized_to_width * 2.0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is simply because the image coordinates have positive y meaning down, where
we want positive y to be up. To correct for this, we simply take the negative of
the last step of the calculation.&lt;/p&gt;

&lt;p&gt;Then we pack the x and y components into a vector (z is -1.0 because all
of our prime rays should go forward from the camera) and normalize it to get a
nice direction vector. Simple, right? This is why the 2x2 sensor 1 unit from the
camera convention is convenient. If we&amp;rsquo;d used any other set of coordinates than
(-1.0&amp;hellip;1.0, -1.0&amp;hellip;1.0) then the image would be off center and/or we&amp;rsquo;d have to
do more calculations to avoid distorting it.&lt;/p&gt;

&lt;p&gt;We could actually stop here - this is a working prime ray generation function.
However, it assumes that the image we&amp;rsquo;re generating is perfectly square and that
the field of view is precisely 90 degrees. It&amp;rsquo;s probably worth adding a
correction for other aspect ratios and different fields of view.&lt;/p&gt;

&lt;p&gt;To adjust for different aspect ratios, we calculate the aspect ratio and
multiply it by the x coordinate. We&amp;rsquo;re assuming that the image will be wider than
it is tall, but most images are so that&amp;rsquo;s good enough for now. If we didn&amp;rsquo;t do
this, the rays would be closer together in the x direction than in the y, which
would cause a distortion in the image (where every pixel is the same size in
both directions).&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/1bef7641a1ce2e52957f65a9022e6a0f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Then we can add another adjustment for field of view. Field of view is the angle
between the left-most ray and the right-most ray (or top- and bottom-most). We
can use simple trigonometry to calculate how much we need to adjust the
coordinates by:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/477ad79cdb635cee87f6e7672d1bc3dc.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;You might have noticed that the origin of all prime rays is exactly (0, 0, 0).
This means that our camera is fixed at those coordinates. It is possible to adapt
this function to place the camera in different locations or orientations, but
we won&amp;rsquo;t need that for now.&lt;/p&gt;

&lt;h2 id=&#34;testing-for-intersections-with-the-sphere&#34;&gt;Testing for Intersections With The Sphere&lt;/h2&gt;

&lt;p&gt;Now that we have our prime rays, we need to know if they intersect with our
sphere. As usual, we&amp;rsquo;ll start with some definitions.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/5cb206e9d4f0dda63a44c1fa5d2908a2.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The basic idea behind this test is that we construct a right-triangle using the
prime ray as the adjacent side and the line between the origin and the center
of the sphere as the hypotenuse. Then we calculate the length of the opposite
side using the Pythagorean Theorem - if that side is smaller than the radius of
the sphere, the ray must intersect the sphere. In practice, we actually do the
check on length-squared values because square roots are expensive to calculate,
but it&amp;rsquo;s the same idea.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/sphere-intersection-test.png&#34; alt=&#34;Sphere Intersection Test&#34; /&gt;&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2fd3e237481614d13a34dc184cb5d106.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;finishing-the-render-method&#34;&gt;Finishing the Render Method&lt;/h2&gt;

&lt;p&gt;Now that we have all of the hard parts done, we simply need to integrate these
functions into the render function and produce our image:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/b2f715736405503985ef66f3732746c5.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;After adding some extra glue code to parse a scene definition and save the
rendered image to a file, we get the resulting image:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bheisler.github.io/static/raytracer-first-render.png&#34; alt=&#34;First Rendered Image&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It isn&amp;rsquo;t very impressive yet, but we&amp;rsquo;ll add more detail to it as we go. In the
&lt;a href=&#34;https://bheisler.github.io/post/writing-raytracer-in-rust-part-2/&#34;&gt;next post&lt;/a&gt;,
we&amp;rsquo;ll add planes, multiple spheres, and some basic lighting effects.&lt;/p&gt;

&lt;p&gt;If you want to try playing around with the code yourself, you can check out the
&lt;a href=&#34;https://github.com/bheisler/raytracer&#34;&gt;GitHub Repository&lt;/a&gt;. If you want to learn
more about 3D rendering in general or raytracing in particular, check out
&lt;a href=&#34;https://www.scratchapixel.com/index.php&#34;&gt;Scratchapixel&lt;/a&gt;, which is the resource
I used while working on this.&lt;/p&gt;

&lt;p&gt;Thanks to Scott Olson and Daniel Hogan for suggesting improvements to an
earlier version of this article.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>