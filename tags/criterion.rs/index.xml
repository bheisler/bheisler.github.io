<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Criterion.Rs on bheisler.github.io</title>
    <link>https://bheisler.github.io/tags/criterion.rs/index.xml</link>
    <description>Recent content in Criterion.Rs on bheisler.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://bheisler.github.io/tags/criterion.rs/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Criterion.rs v0.2 - HTML, Throughput Measurements, API Changes</title>
      <link>https://bheisler.github.io/post/criterion-rs-0-2/</link>
      <pubDate>Mon, 05 Feb 2018 07:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/criterion-rs-0-2/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;m pleased to announce the release of Criterion.rs v0.2, available today. Version 0.2 provides a
number of new features including HTML reports and throughput measurements, fixes a handful of bugs,
and adds a new, more powerful way to configure and construct your benchmarks. It also breaks
backwards compatibility with the 0.1 versions in a number of small but important ways. Read on to
learn more!&lt;/p&gt;

&lt;h2 id=&#34;what-is-criterion-rs&#34;&gt;What is Criterion.rs?&lt;/h2&gt;

&lt;p&gt;Criterion.rs is a statistics-driven benchmarking library for Rust. It provides precise measurements
of changes in the performance of benchmarked code, and gives strong statistical confidence that
apparent performance changes are real and not simply noise. Clear output, a simple API and
reasonable defaults make it easy to use even for developers without a background in statistics.
Unlike the benchmarking harness provided by Rust, Criterion.rs can be used with stable versions of
the compiler.&lt;/p&gt;

&lt;p&gt;If you aren&amp;rsquo;t already using Criterion.rs for your benchmarks, check out the &lt;a href=&#34;https://japaric.github.io/criterion.rs/book/getting_started.html&#34;&gt;Getting Started
guide&lt;/a&gt; or go right to &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;the GitHub
repo&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;new-features&#34;&gt;New Features&lt;/h2&gt;

&lt;p&gt;This is only some of the improvements made to Criterion.rs in v0.2 - for a more complete list, see
the &lt;a href=&#34;https://github.com/japaric/criterion.rs/blob/master/CHANGELOG.md&#34;&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;html-reports&#34;&gt;HTML Reports&lt;/h3&gt;

&lt;p&gt;Criterion.rs now generates an HTML report for each benchmark, including detailed graphs showing the
performance behavior of your code. For an example of the generated report, &lt;a href=&#34;https://japaric.github.io/criterion.rs/book/user_guide/html_report/index.html&#34;&gt;click
here&lt;/a&gt;.
&lt;a href=&#34;http://www.gnuplot.info/&#34;&gt;Gnuplot&lt;/a&gt; must be installed in order to generate reports.&lt;/p&gt;

&lt;p&gt;The reports and other data are now stored in the &lt;code&gt;target/criterion&lt;/code&gt; directory when you run the
benchmarks, which makes them easier to find and means you no longer need to ignore the &lt;code&gt;.criterion&lt;/code&gt;
directory.&lt;/p&gt;

&lt;p&gt;There is still much work to do on expanding the HTML reports, so stay tuned for further enhancements.&lt;/p&gt;

&lt;h3 id=&#34;criterion-bench&#34;&gt;Criterion.bench&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/struct.Criterion.html#method.bench&#34;&gt;&lt;code&gt;bench&lt;/code&gt;&lt;/a&gt;
function has been added to the &lt;code&gt;Criterion&lt;/code&gt; struct, along with two new structures -
&lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/struct.Benchmark.html&#34;&gt;&lt;code&gt;Benchmark&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/struct.ParameterizedBenchmark.html&#34;&gt;&lt;code&gt;ParameterizedBenchmark&amp;lt;T&amp;gt;&lt;/code&gt;&lt;/a&gt;.
These structures provide a powerful builder-style interface to define and configure complex
benchmarks which can perform benchmarks and comparisons that were not possible previously, such as
comparing the performance of a Rust function and an external program over a range of inputs. These
structs also allow for easy per-benchmark configuration of measurement times and other settings.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;c.bench(
    &amp;quot;Fibonacci&amp;quot;,
    Benchmark::new(&amp;quot;Recursive&amp;quot;, |b| b.iter(|| fibonacci_recursive(20)))
        .with_function(&amp;quot;Iterative&amp;quot;, |b| b.iter(|| fibonacci_iterative(20))),
);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;throughput-measurements&#34;&gt;Throughput Measurements&lt;/h3&gt;

&lt;p&gt;Criterion.rs can now estimate the throughput of the code under test. By providing a
&lt;a href=&#34;https://japaric.github.io/criterion.rs/criterion/enum.Throughput.html&#34;&gt;&lt;code&gt;Throughput&lt;/code&gt;&lt;/a&gt; (for
&lt;code&gt;Benchmark&lt;/code&gt;) or &lt;code&gt;Fn(&amp;amp;T) -&amp;gt; Throughput&lt;/code&gt; (for &lt;code&gt;ParameterizedBenchmark&amp;lt;T&amp;gt;&lt;/code&gt;), you can tell Criterion.rs
how many bytes or elements are being processed in each iteration of your benchmark. Criterion.rs
will then use that information to estimate the number of bytes or elements your code can process per
second.&lt;/p&gt;

&lt;h2 id=&#34;breaking-changes&#34;&gt;Breaking Changes&lt;/h2&gt;

&lt;p&gt;Unfortunately, some breaking changes were necessary to implement these new features.&lt;/p&gt;

&lt;h3 id=&#34;builder-methods-take-self-by-value&#34;&gt;Builder Methods Take self by Value&lt;/h3&gt;

&lt;p&gt;All of the builder methods on &lt;code&gt;Criterion&lt;/code&gt; now take &lt;code&gt;self&lt;/code&gt; by value rather than by mutable reference.
This is to simplify chaining multiple methods after calling &lt;code&gt;Criterion::default()&lt;/code&gt;, but existing
code which configures a &lt;code&gt;Criterion&lt;/code&gt; structure may need to be changed or replaced with code that
configures a &lt;code&gt;Benchmark&lt;/code&gt; instead.&lt;/p&gt;

&lt;h3 id=&#34;static-lifetime-for-closure-types&#34;&gt;&amp;lsquo;static Lifetime For Closure Types&lt;/h3&gt;

&lt;p&gt;Most closures passed to Criterion.rs must now have types that live for the &lt;code&gt;&#39;static&lt;/code&gt; lifetime. Note,
the closures themselves don&amp;rsquo;t need to be &lt;code&gt;&#39;static&lt;/code&gt;, but their types do.&lt;/p&gt;

&lt;p&gt;What does this mean for you? You may need to change your benchmarks from &lt;code&gt;|b| b.iter(...)&lt;/code&gt; to
&lt;code&gt;move |b| b.iter(...)&lt;/code&gt;. This does mean that the closures will take ownership of values used inside
the closure, so you may need to clone or &lt;code&gt;Rc&lt;/code&gt; shared test data. Simple closures, like those in the
Fibonacci example above, can remain unchanged - this only affects closures which capture values
from their environment.&lt;/p&gt;

&lt;h3 id=&#34;benchmark-parameters-must-implement-debug&#34;&gt;Benchmark Parameters Must Implement Debug&lt;/h3&gt;

&lt;p&gt;Previously, Criterion.rs required the values for parameterized benchmarks to implement the &lt;code&gt;Display&lt;/code&gt;
trait. This has been changed to require the &lt;code&gt;Debug&lt;/code&gt; trait instead, as that can be easily derived.&lt;/p&gt;

&lt;h2 id=&#34;thank-you&#34;&gt;Thank You&lt;/h2&gt;

&lt;p&gt;Thank you to Damien Levac (@Proksima), @dowwie, Oliver Mader (@b52), Nick Babcock (@nickbabcock),
Steven Fackler (@sfackler), and @llogiq for suggesting improvements to Criterion.rs since the last
release. I&amp;rsquo;d also like to thank Alexander Bulaev (@alexbool) and Paul Mason (@paupino) for
contributing pull requests.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;d like to see your name up here, or if you have ideas, problems or questions, please consider
contributing to Criterion.rs on &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking In Stable Rust With Criterion.rs</title>
      <link>https://bheisler.github.io/post/benchmarking-with-criterion-rs/</link>
      <pubDate>Fri, 12 Jan 2018 19:00:00 -0600</pubDate>
      
      <guid>https://bheisler.github.io/post/benchmarking-with-criterion-rs/</guid>
      <description>

&lt;p&gt;When I initially announced the release of Criterion.rs, I didn&amp;rsquo;t expect that
there would be so much demand for benchmarking on stable Rust. Now, I&amp;rsquo;d like to
announce the release of Criterion.rs 0.1.2, which supports the stable compiler.
This post is an introduction to benchmarking with Criterion.rs and a discussion
of reasons why you might or might not want to do so.&lt;/p&gt;

&lt;h2 id=&#34;what-is-criterion-rs&#34;&gt;What is Criterion.rs?&lt;/h2&gt;

&lt;p&gt;Criterion.rs is a benchmarking library for Rust that aims to bring solid
statistical confidence to benchmarking Rust code, while maintaining good
ease-of-use, even for programmers without a background in statistics. It&amp;rsquo;s
already available on &lt;a href=&#34;https://crates.io/crates/criterion&#34;&gt;Crates.io&lt;/a&gt; and on
&lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It was originally written by &lt;a href=&#34;https://github.com/japaric/&#34;&gt;@japaric&lt;/a&gt;, but was
never released on Crates.io. I (&lt;a href=&#34;https://github.com/bheisler&#34;&gt;@bheisler&lt;/a&gt;)
volunteered to take over maintenance and development a few months ago, and I
published the first version of Criterion.rs to Crates.io in December 2017.&lt;/p&gt;

&lt;h2 id=&#34;getting-started-with-criterion-rs&#34;&gt;Getting Started with Criterion.rs&lt;/h2&gt;

&lt;p&gt;To start with Criterion.rs, add the following to your &lt;code&gt;Cargo.toml&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dev-dependencies]
criterion = &amp;quot;0.1.2&amp;quot;

[[bench]]
name = &amp;quot;my_benchmark&amp;quot;
harness = false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, define a benchmark by creating a file at &lt;code&gt;$PROJECT/benches/my_benchmark.rs&lt;/code&gt; with the following contents.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/2da10e7aaac3011ce1d6328e3a4ffdce.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Finally, run this benchmark with &lt;code&gt;cargo bench&lt;/code&gt;. You should see output similar to the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     Running target/release/deps/example-423eedc43b2b3a93
fib 20                  time:   [26.029 us 26.251 us 26.505 us]
Found 11 outliers among 99 measurements (11.11%)
  6 (6.06%) high mild
  5 (5.05%) high severe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See the &lt;a href=&#34;https://japaric.github.io/criterion.rs/book/getting_started.html&#34;&gt;Getting Started&lt;/a&gt; guide for more details.&lt;/p&gt;

&lt;h2 id=&#34;converting-libtest-benchmarks-to-criterion-rs&#34;&gt;Converting libtest benchmarks to Criterion.rs&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll start with this benchmark as an example:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/61efe654cf235acab9966f8e3e55a5c3.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The first thing to do is update the &lt;code&gt;Cargo.toml&lt;/code&gt; to disable the libtest
benchmark harness:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[bench]]
name = &amp;quot;example&amp;quot;
harness = false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next step is to update the imports:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;#[macro_use]
extern crate criterion;
use criterion::Criterion;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, we can change the &lt;code&gt;bench_fib&lt;/code&gt; function. Remove the &lt;code&gt;#[bench]&lt;/code&gt; and change
the argument to &lt;code&gt;&amp;amp;mut Criterion&lt;/code&gt; instead. The contents of this function need to
change as well:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn bench_fib(c: &amp;amp;mut Criterion) {
    c.bench_function(&amp;quot;fib 20&amp;quot;, |b| b.iter(|| fibonacci(20)));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, we need to invoke some macros to generate a main function, since we
no longer have libtest to provide one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;criterion_group!(benches, bench_fib);
criterion_main!(benches);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that&amp;rsquo;s it! The complete migrated benchmark code is below:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/bheisler/45675855d119ad6f03fa94a5247466fe.js&#34;&gt;&lt;/script&gt;

&lt;h2 id=&#34;the-pitch-why-you-might-want-to-use-criterion-rs&#34;&gt;The Pitch - Why You Might Want to Use Criterion.rs&lt;/h2&gt;

&lt;p&gt;There are a number of reasons to use Criterion.rs.&lt;/p&gt;

&lt;p&gt;The biggest one, the one that drew me to it in the first place, is the
statistical confidence it provides. libtest gives a number and a confidence
interval of some sort, but I cant&amp;rsquo;t even tell if that number is higher or
lower than it was the last time I ran the benchmarks. Even if it is, how could
I tell if that change was due to random noise or a change in the performance of
the code? I&amp;rsquo;ve used Criterion.rs to benchmark and optimize my own projects and
every time I&amp;rsquo;ve seen it show a statistically-significant optimization or
regression it&amp;rsquo;s been real. It&amp;rsquo;s almost fun, tweaking the code and running the
benchmarks to see what happened. I&amp;rsquo;ve never gotten into that sort of flow with
libtest.&lt;/p&gt;

&lt;p&gt;Another big reason is that Criterion.rs is actively maintained and developed.
libtest is not, and the description of the bencher crate on GitHub declares
that new features will not be added. Indeed, it instructs the reader to &amp;ldquo;Go
build a better stable benchmarking library.&amp;rdquo; I hope Criterion.rs is that
library.&lt;/p&gt;

&lt;p&gt;Criterion.rs produces more statistical information than libtest, and generates
helpful charts and graphs to make it more easily understandable to the user.
Additionally, it automatically compares the results of one run with the
previous, without needing to install cargo-benchcmp or manually save benchmark
results to files.&lt;/p&gt;

&lt;p&gt;Finally, Criterion.rs is compatible with stable builds of Rust, where libtest is
not.&lt;/p&gt;

&lt;h2 id=&#34;the-anti-pitch-why-you-might-prefer-libtest&#34;&gt;The Anti-Pitch - Why You Might Prefer libtest&lt;/h2&gt;

&lt;p&gt;With all that said, I would also like to explain some reasons why Criterion.rs
might not be right for everyone.&lt;/p&gt;

&lt;p&gt;For example, libtest benchmarks execute much more quickly than
Criterion.rs benchmarks, especially the small and fast benchmarks. A small
libtest benchmark function can run to completion in less than a second, where
Criterion runs for (by default) at least 8 seconds plus analysis time. If your
project lends itself to many small benchmarks, you&amp;rsquo;d need to configure
Criterion.rs to run shorter tests, where you wouldn&amp;rsquo;t with libtest.&lt;/p&gt;

&lt;p&gt;The corollary to active development is that Criterion.rs&amp;rsquo; API is not yet fully
stablized, where libtest isn&amp;rsquo;t likely to change.&lt;/p&gt;

&lt;p&gt;libtest is also more seamless to use than Criterion.rs. You don&amp;rsquo;t need to mess
around with your &lt;code&gt;Cargo.toml&lt;/code&gt; file to use libtest benchmarks, they just work.
Along the same lines, libtest has the &lt;code&gt;test::black_box&lt;/code&gt; function to prevent
unwanted constant folding, which Criterion.rs can only approximate for now.
Finally, libtest is the only option for benchmarks within your main crate -
both Criterion.rs and bencher can only be used in the &lt;code&gt;benches&lt;/code&gt; folder at
present.&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;I hope I&amp;rsquo;ve convinced you to give Criterion.rs a look. I&amp;rsquo;m excited for the
future of this project and of Rust as a whole, and I hope you are too.&lt;/p&gt;

&lt;p&gt;Although Criterion.rs now supports stable Rust, that doesn&amp;rsquo;t mean that it
itself is stable, or even feature-complete. I certainly plan to continue
polishing and expanding on what Criterion.rs already provides. If you&amp;rsquo;d like to
help with that effort, or if you&amp;rsquo;d like to make suggestions, feature requests
or bug reports, please check out &lt;a href=&#34;https://github.com/japaric/criterion.rs&#34;&gt;the repository on
GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In addition, I hope to work with the Rust team to help define and implement the
necessary changes to Cargo and rustc to use alternate test and benchmark
frameworks. This would make it as seamless to use Criterion.rs as it already is
to use libtest, and will hopefully allow the community to experiment with a
variety of ways to support testing and benchmarking.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>